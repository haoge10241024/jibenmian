#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœŸè´§åŸºæœ¬é¢ç»¼åˆåˆ†æç³»ç»Ÿ
Futures Fundamental Analysis System

ä½œè€…: 7haoge
é‚®ç®±: 953534947@qq.com
åˆ›å»ºæ—¶é—´: 2025.06


ç³»ç»ŸåŠŸèƒ½:
- æœŸè´§åº“å­˜åˆ†æï¼šåŸºäºåº“å­˜å˜åŒ–è¶‹åŠ¿åˆ¤æ–­ä»·æ ¼æ–¹å‘
- æœŸè´§åŸºå·®åˆ†æï¼šåŸºäºç°è´§æœŸè´§ä»·å·®è¿›è¡Œç»Ÿè®¡å¥—åˆ©
- ç»¼åˆä¿¡å·åˆ†æï¼šå¤šç»´åº¦ä¿¡å·å…±æŒ¯æé«˜æŠ•èµ„å¯é æ€§

æŠ€æœ¯æ ˆ:
- Streamlit: Webåº”ç”¨æ¡†æ¶
- AKShare: é‡‘èæ•°æ®æ¥å£
- Pandas/Numpy: æ•°æ®å¤„ç†
- Plotly: äº¤äº’å¼å›¾è¡¨
- Scipy: ç»Ÿè®¡åˆ†æ

å…è´£å£°æ˜:
æœ¬ç³»ç»Ÿä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚
æŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…ã€‚
"""

import streamlit as st
import akshare as ak
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
import io
import base64
from typing import Dict, List, Tuple, Optional
import time
import zipfile
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment
from openpyxl.chart import LineChart, Reference
import tempfile
import os
from dataclasses import dataclass
import concurrent.futures
import pickle
import hashlib
import json
from pathlib import Path

# ==================== é¡µé¢é…ç½® - å¿…é¡»åœ¨æœ€å¼€å§‹ ====================

st.set_page_config(
    page_title="æœŸè´§åŸºæœ¬é¢ç»¼åˆåˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ==================== ç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿ ====================

class CacheManager:
    """é«˜çº§ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir="cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.memory_cache = {}
        self.cache_ttl = {
            'inventory_data': 3600,  # åº“å­˜æ•°æ®ç¼“å­˜1å°æ—¶
            'basis_data': 1800,      # åŸºå·®æ•°æ®ç¼“å­˜30åˆ†é’Ÿ
            'price_data': 1800,      # ä»·æ ¼æ•°æ®ç¼“å­˜30åˆ†é’Ÿ
            'analysis_results': 7200  # åˆ†æç»“æœç¼“å­˜2å°æ—¶
        }
    
    def _get_cache_key(self, data_type: str, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = f"{data_type}_{json.dumps(kwargs, sort_keys=True)}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def _get_cache_file(self, cache_key: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{cache_key}.pkl"
    
    def get(self, data_type: str, **kwargs):
        """è·å–ç¼“å­˜æ•°æ®"""
        cache_key = self._get_cache_key(data_type, **kwargs)
        
        # å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
        if cache_key in self.memory_cache:
            data, timestamp = self.memory_cache[cache_key]
            if time.time() - timestamp < self.cache_ttl.get(data_type, 3600):
                return data
            else:
                del self.memory_cache[cache_key]
        
        # æ£€æŸ¥ç£ç›˜ç¼“å­˜
        cache_file = self._get_cache_file(cache_key)
        if cache_file.exists():
            try:
                with open(cache_file, 'rb') as f:
                    data, timestamp = pickle.load(f)
                
                if time.time() - timestamp < self.cache_ttl.get(data_type, 3600):
                    # åŠ è½½åˆ°å†…å­˜ç¼“å­˜
                    self.memory_cache[cache_key] = (data, timestamp)
                    return data
                else:
                    cache_file.unlink()  # åˆ é™¤è¿‡æœŸæ–‡ä»¶
            except Exception:
                cache_file.unlink()  # åˆ é™¤æŸåæ–‡ä»¶
        
        return None
    
    def set(self, data_type: str, data, **kwargs):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        cache_key = self._get_cache_key(data_type, **kwargs)
        timestamp = time.time()
        
        # ä¿å­˜åˆ°å†…å­˜ç¼“å­˜
        self.memory_cache[cache_key] = (data, timestamp)
        
        # ä¿å­˜åˆ°ç£ç›˜ç¼“å­˜
        cache_file = self._get_cache_file(cache_key)
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump((data, timestamp), f)
        except Exception as e:
            st.warning(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    def clear_expired(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        current_time = time.time()
        
        # æ¸…ç†å†…å­˜ç¼“å­˜
        expired_keys = []
        for key, (data, timestamp) in self.memory_cache.items():
            if current_time - timestamp > max(self.cache_ttl.values()):
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.memory_cache[key]
        
        # æ¸…ç†ç£ç›˜ç¼“å­˜
        for cache_file in self.cache_dir.glob("*.pkl"):
            try:
                with open(cache_file, 'rb') as f:
                    data, timestamp = pickle.load(f)
                if current_time - timestamp > max(self.cache_ttl.values()):
                    cache_file.unlink()
            except Exception:
                cache_file.unlink()

# å…¨å±€ç¼“å­˜ç®¡ç†å™¨
@st.cache_resource
def get_cache_manager():
    return CacheManager()

cache_manager = get_cache_manager()

# ==================== è¾…åŠ©å‡½æ•° ====================

def get_analysis_id(analysis_type: str, **kwargs) -> str:
    """ç”Ÿæˆåˆ†æIDç”¨äºç¼“å­˜"""
    key_parts = [analysis_type]
    for key, value in sorted(kwargs.items()):
        if isinstance(value, list):
            key_parts.append(f"{key}_{hash(tuple(value))}")
        else:
            key_parts.append(f"{key}_{value}")
    return "_".join(str(part) for part in key_parts)

def get_cached_analysis_result(analysis_id: str):
    """è·å–ç¼“å­˜çš„åˆ†æç»“æœ"""
    return cache_manager.get(f"analysis_{analysis_id}")

def cache_analysis_result(analysis_id: str, result):
    """ç¼“å­˜åˆ†æç»“æœ"""
    cache_manager.set(f"analysis_{analysis_id}", result, ttl=3600)  # 1å°æ—¶è¿‡æœŸ

# ==================== ç¼“å­˜è£…é¥°å™¨å‡½æ•° ====================

@st.cache_data(ttl=1800)  # 30åˆ†é’Ÿç¼“å­˜
def cached_futures_inventory_em(symbol: str) -> Optional[pd.DataFrame]:
    """ç¼“å­˜çš„æœŸè´§åº“å­˜æ•°æ®è·å–"""
    try:
        df = ak.futures_inventory_em(symbol=symbol)
        if df is not None and not df.empty:
            return df
        return None
    except Exception:
        return None

@st.cache_data(ttl=1800)  # 30åˆ†é’Ÿç¼“å­˜  
def cached_futures_hist_em(symbol: str) -> Optional[pd.DataFrame]:
    """ç¼“å­˜çš„æœŸè´§å†å²æ•°æ®è·å–"""
    try:
        # ä½¿ç”¨ futures_main_sina æ¥å£ï¼Œè¿”å›çš„åˆ—ååŒ…å« 'æ”¶ç›˜ä»·'
        df = ak.futures_main_sina(symbol=symbol)
        if df is not None and not df.empty:
            # å¤„ç†æ—¥æœŸåˆ—
            if 'æ—¥æœŸ' in df.columns:
                # å¦‚æœå·²ç»æœ‰æ—¥æœŸåˆ—ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
            else:
                # å¦‚æœæ²¡æœ‰æ—¥æœŸåˆ—ï¼Œæ£€æŸ¥ç´¢å¼•æ˜¯å¦æ˜¯æ—¥æœŸ
                if hasattr(df.index, 'dtype') and 'datetime' in str(df.index.dtype):
                    df['æ—¥æœŸ'] = pd.to_datetime(df.index)
                else:
                    # å°è¯•ä»å…¶ä»–å¯èƒ½çš„åˆ—åè·å–æ—¥æœŸ
                    date_columns = ['date', 'Date', 'DATE', 'time', 'Time']
                    date_col_found = False
                    for col in date_columns:
                        if col in df.columns:
                            df['æ—¥æœŸ'] = pd.to_datetime(df[col], errors='coerce')
                            date_col_found = True
                            break
                    
                    if not date_col_found:
                        # å¦‚æœæ‰¾ä¸åˆ°æ—¥æœŸåˆ—ï¼Œä½¿ç”¨ç´¢å¼•ä½œä¸ºæ—¥æœŸ
                        df['æ—¥æœŸ'] = pd.to_datetime(df.index, errors='coerce')
            
            # ç»Ÿä¸€æ”¶ç›˜ä»·åˆ—å
            if 'æ”¶ç›˜ä»·' in df.columns:
                df['æ”¶ç›˜'] = df['æ”¶ç›˜ä»·']
            elif 'close' in df.columns:
                df['æ”¶ç›˜'] = df['close']
            elif 'Close' in df.columns:
                df['æ”¶ç›˜'] = df['Close']
            elif 'current_price' in df.columns:
                df['æ”¶ç›˜'] = df['current_price']
            
            # è¿‡æ»¤æ‰æ— æ•ˆçš„æ—¥æœŸ
            df = df.dropna(subset=['æ—¥æœŸ'])
            
            # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹ä¸”æœ‰æ•ˆ
            if len(df) > 0 and df['æ—¥æœŸ'].dtype == 'datetime64[ns]':
                # è¿‡æ»¤æ‰å¼‚å¸¸æ—¥æœŸï¼ˆå¦‚1970å¹´çš„æ•°æ®ï¼‰
                df = df[df['æ—¥æœŸ'] > pd.Timestamp('2000-01-01')]
                
            return df if len(df) > 0 else None
        return None
    except Exception as e:
        print(f"è·å–ä»·æ ¼æ•°æ®å¤±è´¥: {e}")
        return None

@st.cache_data(ttl=3600)  # 1å°æ—¶ç¼“å­˜
def cached_futures_spot_price(symbol: str) -> Optional[pd.DataFrame]:
    """ç¼“å­˜çš„ç°è´§ä»·æ ¼æ•°æ®è·å–"""
    try:
        df = ak.futures_spot_price_em(symbol=symbol)
        if df is not None and not df.empty:
            return df
        return None
    except Exception:
        return None

@st.cache_data(ttl=3600)  # 1å°æ—¶ç¼“å­˜
def cached_futures_basis_analysis(symbol: str, end_date: str, days_back: int = 30) -> Optional[pd.DataFrame]:
    """ç¼“å­˜çš„åŸºå·®åˆ†ææ•°æ®"""
    try:
        # è¿™é‡Œåº”è¯¥è°ƒç”¨åŸºå·®åˆ†æçš„å…·ä½“å®ç°
        # ç”±äºakshareå¯èƒ½æ²¡æœ‰ç›´æ¥çš„åŸºå·®æ¥å£ï¼Œè¿™é‡Œè¿”å›None
        # å®é™…å®ç°ä¸­éœ€è¦é€šè¿‡ç°è´§ä»·æ ¼å’ŒæœŸè´§ä»·æ ¼è®¡ç®—åŸºå·®
        return None
    except Exception:
        return None

# ==================== æ•°æ®è·å–ä¼˜åŒ– ====================

@st.cache_data(ttl=3600, max_entries=1000, show_spinner=False)
def cached_futures_spot_price_daily(start_day, end_day, vars_list):
    """ä¼˜åŒ–çš„åŸºå·®æ•°æ®è·å–"""
    # å…ˆå°è¯•ä»é«˜çº§ç¼“å­˜è·å–
    cache_key = f"{start_day}_{end_day}_{','.join(vars_list)}"
    cached_data = cache_manager.get('basis_data', cache_key=cache_key)
    if cached_data is not None:
        return cached_data
    
    try:
        data = ak.futures_spot_price_daily(
            start_day=start_day,
            end_day=end_day,
            vars_list=vars_list
        )
        if data is not None and not data.empty:
            # ä¿å­˜åˆ°é«˜çº§ç¼“å­˜
            cache_manager.set('basis_data', data, cache_key=cache_key)
        return data
    except Exception:
        return None

# å¹¶è¡Œæ•°æ®è·å–
def get_multiple_data_parallel(symbols: List[str], data_type: str = 'inventory', max_workers: int = 8):
    """å¹¶è¡Œè·å–å¤šä¸ªå“ç§çš„æ•°æ®"""
    results = {}
    
    def fetch_data(symbol):
        try:
            if data_type == 'inventory':
                return symbol, cached_futures_inventory_em(symbol)
            elif data_type == 'price':
                return symbol, cached_futures_hist_em(f"{symbol}ä¸»è¿")
            else:
                return symbol, None
        except Exception:
            return symbol, None
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_symbol = {executor.submit(fetch_data, symbol): symbol for symbol in symbols}
        
        for future in concurrent.futures.as_completed(future_to_symbol):
            symbol, data = future.result()
            if data is not None and not data.empty:
                results[symbol] = data
    
    return results

# ==================== ä¼šè¯çŠ¶æ€ç®¡ç† ====================

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'analysis_cache' not in st.session_state:
        st.session_state.analysis_cache = {}
    
    if 'current_analysis_id' not in st.session_state:
        st.session_state.current_analysis_id = None
    
    if 'inventory_results' not in st.session_state:
        st.session_state.inventory_results = None
    
    if 'basis_results' not in st.session_state:
        st.session_state.basis_results = None
    
    if 'show_charts' not in st.session_state:
        st.session_state.show_charts = {}

# ==================== æŠ¥å‘Šå¯¼å‡ºç³»ç»Ÿ ====================

class ReportExporter:
    """æŠ¥å‘Šå¯¼å‡ºå™¨"""
    
    def __init__(self):
        self.temp_dir = Path(tempfile.gettempdir()) / "futures_analysis"
        self.temp_dir.mkdir(exist_ok=True)
    
    def export_inventory_excel(self, results_df: pd.DataFrame, inventory_trends: Dict, data_dict: Dict) -> Path:
        """å¯¼å‡ºåº“å­˜åˆ†æExcelæŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = self.temp_dir / f"åº“å­˜åˆ†ææŠ¥å‘Š_{timestamp}.xlsx"
        
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            # åˆ†æç»“æœ
            results_df.to_excel(writer, sheet_name='åˆ†æç»“æœ', index=False)
            
            # è¶‹åŠ¿æ±‡æ€»
            trend_summary = pd.DataFrame({
                'è¶‹åŠ¿ç±»å‹': ['ç´¯åº“å“ç§', 'å»åº“å“ç§', 'ç¨³å®šå“ç§'],
                'å“ç§æ•°é‡': [len(inventory_trends['ç´¯åº“å“ç§']), 
                           len(inventory_trends['å»åº“å“ç§']), 
                           len(inventory_trends['åº“å­˜ç¨³å®šå“ç§'])],
                'å“ç§åˆ—è¡¨': [', '.join(inventory_trends['ç´¯åº“å“ç§']),
                           ', '.join(inventory_trends['å»åº“å“ç§']),
                           ', '.join(inventory_trends['åº“å­˜ç¨³å®šå“ç§'])]
            })
            trend_summary.to_excel(writer, sheet_name='è¶‹åŠ¿æ±‡æ€»', index=False)
            
            # åŸå§‹æ•°æ®ï¼ˆå‰5ä¸ªå“ç§ï¼‰
            for i, (symbol, df) in enumerate(list(data_dict.items())[:5]):
                df.to_excel(writer, sheet_name=f'{symbol}_æ•°æ®', index=False)
        
        return filepath
    
    def export_basis_excel(self, opportunities: List, analysis_stats: Dict) -> Path:
        """å¯¼å‡ºåŸºå·®åˆ†æExcelæŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = self.temp_dir / f"åŸºå·®åˆ†ææŠ¥å‘Š_{timestamp}.xlsx"
        
        # åˆ›å»ºç»“æœæ•°æ®
        results_data = []
        for opp in opportunities:
            results_data.append({
                'å“ç§': opp.name,
                'ä»£ç ': opp.variety,
                'æœºä¼šç±»å‹': opp.opportunity_type,
                'ç½®ä¿¡åº¦(%)': opp.confidence,
                'é¢„æœŸæ”¶ç›Š(%)': opp.expected_return,
                'é£é™©ç­‰çº§': opp.risk_level,
                'å»ºè®®æŒä»“(å¤©)': opp.holding_period,
                'Z-Score': opp.z_score,
                'å½“å‰åŸºå·®': opp.current_basis,
                'å†å²å‡å€¼': opp.basis_mean,
                'å†å²æ ‡å‡†å·®': opp.basis_std,
                'ç™¾åˆ†ä½æ•°': opp.percentile
            })
        
        results_df = pd.DataFrame(results_data)
        
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            # åˆ†æç»“æœ
            results_df.to_excel(writer, sheet_name='æŠ•èµ„æœºä¼š', index=False)
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats_df = pd.DataFrame({
                'ç»Ÿè®¡é¡¹ç›®': ['æˆåŠŸè·å–æ•°æ®', 'è·å–å¤±è´¥', 'æ£€æµ‹åˆ°ä¿¡å·', 'æ€»æœºä¼šæ•°'],
                'æ•°é‡': [len(analysis_stats.get('successful_varieties', [])),
                        len(analysis_stats.get('failed_varieties', [])),
                        len(analysis_stats.get('analyzed_varieties', [])),
                        len(opportunities)]
            })
            stats_df.to_excel(writer, sheet_name='åˆ†æç»Ÿè®¡', index=False)
        
        return filepath
    
    def create_comprehensive_report(self, inventory_results: Tuple, basis_results: Tuple) -> Path:
        """åˆ›å»ºç»¼åˆåˆ†ææŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = self.temp_dir / f"ç»¼åˆåˆ†ææŠ¥å‘Š_{timestamp}.xlsx"
        
        results_df, inventory_trends, data_dict = inventory_results
        opportunities, strategy = basis_results
        
        # ä¿¡å·å…±æŒ¯åˆ†æ
        buy_basis_symbols = [opp.variety for opp in opportunities if 'ä¹°åŸºå·®' in opp.opportunity_type]
        sell_basis_symbols = [opp.variety for opp in opportunities if 'å–åŸºå·®' in opp.opportunity_type]
        
        short_resonance = set(inventory_trends['ç´¯åº“å“ç§']) & set(buy_basis_symbols)
        long_resonance = set(inventory_trends['å»åº“å“ç§']) & set(sell_basis_symbols)
        conflict_1 = set(inventory_trends['ç´¯åº“å“ç§']) & set(sell_basis_symbols)
        conflict_2 = set(inventory_trends['å»åº“å“ç§']) & set(buy_basis_symbols)
        
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            # åº“å­˜åˆ†æç»“æœ
            results_df.to_excel(writer, sheet_name='åº“å­˜åˆ†æ', index=False)
            
            # åŸºå·®åˆ†æç»“æœ
            basis_data = []
            for opp in opportunities:
                basis_data.append({
                    'å“ç§': opp.name,
                    'ä»£ç ': opp.variety,
                    'æœºä¼šç±»å‹': opp.opportunity_type,
                    'ç½®ä¿¡åº¦(%)': opp.confidence,
                    'é¢„æœŸæ”¶ç›Š(%)': opp.expected_return,
                    'é£é™©ç­‰çº§': opp.risk_level
                })
            basis_df = pd.DataFrame(basis_data)
            basis_df.to_excel(writer, sheet_name='åŸºå·®åˆ†æ', index=False)
            
            # ä¿¡å·å…±æŒ¯åˆ†æ
            resonance_data = []
            
            # åšç©ºå…±æŒ¯
            for symbol in short_resonance:
                resonance_data.append({
                    'å“ç§': symbol,
                    'ä¿¡å·ç±»å‹': 'åšç©ºå…±æŒ¯',
                    'åº“å­˜ä¿¡å·': 'ç´¯åº“',
                    'åŸºå·®ä¿¡å·': 'ä¹°åŸºå·®',
                    'æŠ•èµ„å»ºè®®': 'çœ‹ç©ºï¼Œè€ƒè™‘åšç©ºæ“ä½œ'
                })
            
            # åšå¤šå…±æŒ¯
            for symbol in long_resonance:
                resonance_data.append({
                    'å“ç§': symbol,
                    'ä¿¡å·ç±»å‹': 'åšå¤šå…±æŒ¯',
                    'åº“å­˜ä¿¡å·': 'å»åº“',
                    'åŸºå·®ä¿¡å·': 'å–åŸºå·®',
                    'æŠ•èµ„å»ºè®®': 'çœ‹å¤šï¼Œè€ƒè™‘åšå¤šæ“ä½œ'
                })
            
            # ä¿¡å·å†²çª
            for symbol in conflict_1:
                resonance_data.append({
                    'å“ç§': symbol,
                    'ä¿¡å·ç±»å‹': 'ä¿¡å·å†²çª',
                    'åº“å­˜ä¿¡å·': 'ç´¯åº“',
                    'åŸºå·®ä¿¡å·': 'å–åŸºå·®',
                    'æŠ•èµ„å»ºè®®': 'è§‚æœ›æˆ–æ·±å…¥åˆ†æ'
                })
            
            for symbol in conflict_2:
                resonance_data.append({
                    'å“ç§': symbol,
                    'ä¿¡å·ç±»å‹': 'ä¿¡å·å†²çª',
                    'åº“å­˜ä¿¡å·': 'å»åº“',
                    'åŸºå·®ä¿¡å·': 'ä¹°åŸºå·®',
                    'æŠ•èµ„å»ºè®®': 'è§‚æœ›æˆ–æ·±å…¥åˆ†æ'
                })
            
            if resonance_data:
                resonance_df = pd.DataFrame(resonance_data)
                resonance_df.to_excel(writer, sheet_name='ä¿¡å·å…±æŒ¯åˆ†æ', index=False)
            
            # ç»¼åˆæ‘˜è¦
            total_analyzed = len(set(inventory_trends['ç´¯åº“å“ç§'] + inventory_trends['å»åº“å“ç§']) | 
                               set(buy_basis_symbols + sell_basis_symbols))
            resonance_rate = (len(short_resonance) + len(long_resonance)) / max(total_analyzed, 1) * 100
            
            summary_data = [{
                'åˆ†ææ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'åº“å­˜åˆ†æå“ç§æ•°': len(results_df),
                'åŸºå·®åˆ†ææœºä¼šæ•°': len(opportunities),
                'åšç©ºä¿¡å·å…±æŒ¯': len(short_resonance),
                'åšå¤šä¿¡å·å…±æŒ¯': len(long_resonance),
                'ä¿¡å·å†²çªå“ç§': len(conflict_1) + len(conflict_2),
                'å…±æŒ¯ç‡(%)': f"{resonance_rate:.1f}%"
            }]
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(writer, sheet_name='ç»¼åˆæ‘˜è¦', index=False)
        
        return filepath

def get_report_exporter() -> ReportExporter:
    """è·å–æŠ¥å‘Šå¯¼å‡ºå™¨å®ä¾‹"""
    return ReportExporter()


# ==================== åŸºå·®åˆ†æç›¸å…³ç±»å’Œå‡½æ•° ====================

@dataclass
class BasisOpportunity:
    """åŸºå·®æŠ•èµ„æœºä¼šæ•°æ®ç±»"""
    variety: str
    name: str
    current_basis: float
    basis_mean: float
    basis_std: float
    z_score: float
    percentile: float
    opportunity_type: str
    confidence: float
    risk_level: str
    expected_return: float
    holding_period: int

class FuturesBasisStrategy:
    """æœŸè´§åŸºå·®æŠ•èµ„ç­–ç•¥åˆ†æç³»ç»Ÿ"""
    
    def __init__(self):
        self.contracts = None
        self.opportunities = []
        self.analysis_results = {}
        
    def get_main_contracts(self) -> pd.DataFrame:
        """è·å–æ‰€æœ‰ä¸»åŠ›åˆçº¦å“ç§ä¿¡æ¯"""
        # å…ˆå°è¯•ä»ç¼“å­˜è·å–
        cached_contracts = cache_manager.get('contracts_data')
        if cached_contracts is not None:
            self.contracts = cached_contracts
            return cached_contracts
        
        try:
            contract_name = ak.futures_display_main_sina()
            contract_name['symbol'] = contract_name['symbol'].str.replace('0', '')
            contracts = contract_name[['symbol', 'name']]
            
            # ä¿å­˜åˆ°ç¼“å­˜
            cache_manager.set('contracts_data', contracts)
            self.contracts = contracts
            return contracts
        except Exception as e:
            st.error(f"è·å–åˆçº¦ä¿¡æ¯å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_basis_data(self, variety: str, start_day: str, end_day: str) -> Optional[pd.DataFrame]:
        """è·å–å¹¶å¤„ç†åŸºå·®æ•°æ®"""
        try:
            df = cached_futures_spot_price_daily(
                start_day=start_day,
                end_day=end_day,
                vars_list=[variety]
            )
            
            if df is None or df.empty:
                return None
            
            # æ•°æ®é¢„å¤„ç†
            df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')
            df['basis'] = df['spot_price'] - df['dominant_contract_price']
            df['basis_rate'] = df['basis'] / df['spot_price'] * 100
            
            # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
            df = self._add_technical_indicators(df)
            
            return df.sort_values('date')
            
        except Exception as e:
            return None
    
    def _add_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æŠ€æœ¯åˆ†ææŒ‡æ ‡"""
        # åŸºå·®ç§»åŠ¨å¹³å‡
        df['basis_ma5'] = df['basis'].rolling(window=5, min_periods=1).mean()
        df['basis_ma10'] = df['basis'].rolling(window=10, min_periods=1).mean()
        
        # åŸºå·®å¸ƒæ—å¸¦
        rolling_std = df['basis'].rolling(window=10, min_periods=1).std()
        df['basis_upper'] = df['basis_ma10'] + 2 * rolling_std
        df['basis_lower'] = df['basis_ma10'] - 2 * rolling_std
        
        # åŸºå·®RSI
        df['basis_rsi'] = self._calculate_rsi(df['basis'])
        
        # ä»·æ ¼åŠ¨é‡
        df['price_momentum'] = df['spot_price'].pct_change(5) * 100
        df['futures_momentum'] = df['dominant_contract_price'].pct_change(5) * 100
        
        return df
    
    def _calculate_rsi(self, series: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—RSIæŒ‡æ ‡"""
        delta = series.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def analyze_basis_opportunity(self, df: pd.DataFrame, variety: str, name: str) -> Optional[BasisOpportunity]:
        """åˆ†æåŸºå·®æŠ•èµ„æœºä¼š"""
        if df is None or len(df) < 10:
            return None
        
        # åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡
        basis_mean = df['basis'].mean()
        basis_std = df['basis'].std()
        current_basis = df['basis'].iloc[-1]
        
        if basis_std == 0:
            return None
        
        # æ ‡å‡†åŒ–åŸºå·®ï¼ˆZ-scoreï¼‰
        z_score = (current_basis - basis_mean) / basis_std
        
        # åŸºå·®åˆ†ä½æ•°
        basis_percentile = (df['basis'] <= current_basis).mean() * 100
        
        # è¶‹åŠ¿åˆ†æ
        recent_trend = df['basis'].tail(5).mean() - df['basis'].head(5).mean()
        volatility = df['basis'].std() / abs(df['basis'].mean()) if df['basis'].mean() != 0 else float('inf')
        
        # æŠ€æœ¯æŒ‡æ ‡åˆ†æ
        current_rsi = df['basis_rsi'].iloc[-1] if not pd.isna(df['basis_rsi'].iloc[-1]) else 50
        
        # å¸ƒæ—å¸¦ä½ç½®
        current_upper = df['basis_upper'].iloc[-1]
        current_lower = df['basis_lower'].iloc[-1]
        bb_position = (current_basis - current_lower) / (current_upper - current_lower) if (current_upper - current_lower) != 0 else 0.5
        
        # æŠ•èµ„æœºä¼šè¯†åˆ«
        opportunity_type, confidence, expected_return, holding_period = self._identify_opportunity(
            z_score, basis_percentile, recent_trend, current_rsi, bb_position, volatility
        )
        
        if opportunity_type == "æ— æ˜æ˜¾æœºä¼š":
            return None
        
        # é£é™©è¯„ä¼°
        risk_level = self._assess_risk(volatility, abs(z_score), df)
        
        return BasisOpportunity(
            variety=variety,
            name=name,
            current_basis=current_basis,
            basis_mean=basis_mean,
            basis_std=basis_std,
            z_score=z_score,
            percentile=basis_percentile,
            opportunity_type=opportunity_type,
            confidence=confidence,
            risk_level=risk_level,
            expected_return=expected_return,
            holding_period=holding_period
        )
    
    def _identify_opportunity(self, z_score: float, percentile: float, trend: float, 
                            rsi: float, bb_position: float, volatility: float) -> Tuple[str, float, float, int]:
        """è¯†åˆ«æŠ•èµ„æœºä¼š"""
        
        # åŸºå·®å¼‚å¸¸ç¨‹åº¦è¯„åˆ†
        extreme_score = abs(z_score)
        
        # è¶‹åŠ¿åè½¬ä¿¡å·
        reversal_signal = 0
        if z_score < -1.2 and trend > 0:
            reversal_signal += 1
        if z_score > 1.2 and trend < 0:
            reversal_signal += 1
        
        # RSIè¶…ä¹°è¶…å–ä¿¡å·
        rsi_signal = 0
        if rsi < 35:
            rsi_signal = 1
        elif rsi > 65:
            rsi_signal = -1
        
        # å¸ƒæ—å¸¦ä¿¡å·
        bb_signal = 0
        if bb_position < 0.25:
            bb_signal = 1
        elif bb_position > 0.75:
            bb_signal = -1
        
        # ç»¼åˆè¯„åˆ†
        if z_score < -1.5:
            opportunity_type = "ä¹°åŸºå·®æœºä¼š"
            base_confidence = min(extreme_score * 30, 85)
            expected_return = min(abs(z_score) * 2, 8)
            holding_period = max(10, int(20 - extreme_score * 3))
            
        elif z_score > 1.5:
            opportunity_type = "å–åŸºå·®æœºä¼š"
            base_confidence = min(extreme_score * 30, 85)
            expected_return = min(abs(z_score) * 2, 8)
            holding_period = max(10, int(20 - extreme_score * 3))
            
        elif abs(z_score) > 1.0:
            if z_score < 0:
                opportunity_type = "ä¹°åŸºå·®æœºä¼š"
            else:
                opportunity_type = "å–åŸºå·®æœºä¼š"
            base_confidence = min(extreme_score * 25, 70)
            expected_return = min(abs(z_score) * 1.5, 5)
            holding_period = max(15, int(25 - extreme_score * 2))
            
        elif abs(z_score) > 0.8:
            if z_score < 0:
                opportunity_type = "å¼±ä¹°åŸºå·®æœºä¼š"
            else:
                opportunity_type = "å¼±å–åŸºå·®æœºä¼š"
            base_confidence = min(extreme_score * 20, 50)
            expected_return = min(abs(z_score) * 1.2, 3)
            holding_period = max(20, int(30 - extreme_score * 2))
            
        else:
            opportunity_type = "æ— æ˜æ˜¾æœºä¼š"
            base_confidence = 0
            expected_return = 0
            holding_period = 0
        
        # è°ƒæ•´ç½®ä¿¡åº¦
        if opportunity_type != "æ— æ˜æ˜¾æœºä¼š":
            confidence_adjustment = reversal_signal * 8 + rsi_signal * 4 + bb_signal * 4
            final_confidence = max(0, min(95, base_confidence + confidence_adjustment))
            
            # æ³¢åŠ¨ç‡è°ƒæ•´
            if volatility > 0.6:
                final_confidence *= 0.85
            elif volatility < 0.15:
                final_confidence *= 1.05
                
            final_confidence = min(95, final_confidence)
        else:
            final_confidence = 0
        
        return opportunity_type, final_confidence, expected_return, holding_period
    
    def _assess_risk(self, volatility: float, z_score_abs: float, df: pd.DataFrame) -> str:
        """è¯„ä¼°æŠ•èµ„é£é™©ç­‰çº§"""
        risk_score = 0
        
        # æ³¢åŠ¨ç‡é£é™©
        if volatility > 0.5:
            risk_score += 3
        elif volatility > 0.3:
            risk_score += 2
        elif volatility > 0.15:
            risk_score += 1
        
        # æç«¯ç¨‹åº¦é£é™©
        if z_score_abs > 3:
            risk_score += 2
        elif z_score_abs > 2.5:
            risk_score += 1
        
        # æ•°æ®è´¨é‡é£é™©
        if len(df) < 15:
            risk_score += 1
        
        # ä»·æ ¼è¶‹åŠ¿ä¸€è‡´æ€§
        spot_trend = df['spot_price'].iloc[-1] - df['spot_price'].iloc[0]
        futures_trend = df['dominant_contract_price'].iloc[-1] - df['dominant_contract_price'].iloc[0]
        if spot_trend * futures_trend < 0:
            risk_score += 1
        
        if risk_score >= 5:
            return "é«˜é£é™©"
        elif risk_score >= 3:
            return "ä¸­é£é™©"
        else:
            return "ä½é£é™©"
    
    def run_analysis_streamlit(self, end_day: str, days_back: int = 30, min_confidence: float = 50.0, 
                              progress_callback=None) -> List[BasisOpportunity]:
        """è¿è¡Œå®Œæ•´çš„åŸºå·®åˆ†æï¼ˆStreamlitç‰ˆæœ¬ï¼‰"""
        
        # ç”Ÿæˆåˆ†æID
        analysis_id = get_analysis_id('basis', end_day=end_day, days_back=days_back, min_confidence=min_confidence)
        
        # æ£€æŸ¥ç¼“å­˜
        cached_result = get_cached_analysis_result(analysis_id)
        if cached_result is not None:
            self.opportunities = cached_result['opportunities']
            self.analysis_results = cached_result['analysis_results']
            if hasattr(cached_result, 'analysis_stats'):
                self.analysis_stats = cached_result['analysis_stats']
            return self.opportunities
        
        # è·å–åˆçº¦ä¿¡æ¯
        if self.contracts is None:
            self.contracts = self.get_main_contracts()
        
        if self.contracts.empty:
            st.error("æ— æ³•è·å–åˆçº¦ä¿¡æ¯")
            return []
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.strptime(end_day, "%Y%m%d")
        start_date = end_date - timedelta(days=days_back)
        start_day = start_date.strftime("%Y%m%d")
        
        opportunities = []
        successful_varieties = []
        failed_varieties = []
        analyzed_varieties = []
        
        total_varieties = len(self.contracts)
        
        # éå†æ‰€æœ‰å“ç§
        for idx, row in self.contracts.iterrows():
            symbol = row['symbol']
            name = row['name']
            
            if progress_callback:
                progress_callback(idx + 1, total_varieties, f"æ­£åœ¨åˆ†æ {name} ({symbol})")
            
            # è·å–æ•°æ®
            df = self.get_basis_data(symbol, start_day, end_day)
            
            if df is not None and len(df) >= 10:
                successful_varieties.append({'symbol': symbol, 'name': name, 'data_points': len(df)})
                
                # åˆ†ææŠ•èµ„æœºä¼š
                opportunity = self.analyze_basis_opportunity(df, symbol, name)
                
                if opportunity:
                    analyzed_varieties.append({
                        'symbol': symbol, 
                        'name': name, 
                        'z_score': opportunity.z_score,
                        'confidence': opportunity.confidence,
                        'opportunity_type': opportunity.opportunity_type,
                        'current_basis': opportunity.current_basis,
                        'basis_mean': opportunity.basis_mean
                    })
                    
                    if opportunity.confidence >= min_confidence:
                        opportunities.append(opportunity)
                        self.analysis_results[symbol] = df
            else:
                failed_varieties.append({'symbol': symbol, 'name': name, 'reason': 'æ•°æ®ä¸è¶³' if df is not None else 'è·å–å¤±è´¥'})
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.05)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        opportunities.sort(key=lambda x: x.confidence, reverse=True)
        self.opportunities = opportunities
        
        # å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        self.analysis_stats = {
            'successful_varieties': successful_varieties,
            'failed_varieties': failed_varieties,
            'analyzed_varieties': analyzed_varieties
        }
        
        # ç¼“å­˜ç»“æœ
        result_to_cache = {
            'opportunities': opportunities,
            'analysis_results': self.analysis_results,
            'analysis_stats': self.analysis_stats
        }
        cache_analysis_result(analysis_id, result_to_cache)
        
        return opportunities

# ==================== åº“å­˜åˆ†æç›¸å…³ç±»å’Œå‡½æ•° ====================

class FuturesInventoryAnalyzer:
    def __init__(self, confidence_level: float = 0.95):
        self.confidence_level = confidence_level
        self.seasonal_periods = {
            'å†œäº§å“': 12,
            'å·¥ä¸šå“': 4,
            'èƒ½æºåŒ–å·¥': 4
        }
        
    def calculate_seasonal_factor(self, df: pd.DataFrame, category: str) -> pd.Series:
        """è®¡ç®—å­£èŠ‚æ€§å› å­"""
        try:
            if len(df) < 5:
                return pd.Series([0])
            
            period = self.seasonal_periods.get(category, 12)
            period = min(period, len(df))  # ç¡®ä¿å‘¨æœŸä¸è¶…è¿‡æ•°æ®é•¿åº¦
            
            if period < 2:
                return pd.Series([0])
            
            seasonal = df['åº“å­˜'].rolling(window=period, min_periods=1).mean()
            
            # ç¡®ä¿è¿”å›çš„Seriesä¸åŒ…å«nan
            if seasonal.empty or seasonal.isna().all():
                return pd.Series([0])
            
            # ç”¨æœ€åä¸€ä¸ªæœ‰æ•ˆå€¼å¡«å……nan
            seasonal = seasonal.fillna(method='ffill').fillna(0)
            
            return seasonal
            
        except Exception as e:
            print(f"è®¡ç®—å­£èŠ‚æ€§å› å­æ—¶å‡ºé”™: {e}")
            return pd.Series([0])
    
    def calculate_inventory_velocity(self, df: pd.DataFrame, days: int = 30) -> float:
        """è®¡ç®—åº“å­˜å‘¨è½¬ç‡"""
        try:
            if len(df) < 5:
                return 0.0
            
            recent_data = df.tail(min(days, len(df)))
            
            if len(recent_data) == 0:
                return 0.0
            
            # è®¡ç®—å¹³å‡åº“å­˜
            avg_inventory = recent_data['åº“å­˜'].mean()
            if pd.isna(avg_inventory) or avg_inventory <= 0:
                return 0.0
            
            # è®¡ç®—åº“å­˜å˜åŒ–çš„ç»å¯¹å€¼æ€»å’Œ
            inventory_changes = recent_data['å¢å‡'].abs().sum()
            if pd.isna(inventory_changes):
                return 0.0
            
            # åº“å­˜å‘¨è½¬ç‡ = åº“å­˜å˜åŒ–æ€»é‡ / å¹³å‡åº“å­˜
            velocity = inventory_changes / avg_inventory
            
            # ç¡®ä¿ç»“æœä¸æ˜¯nan
            if pd.isna(velocity):
                return 0.0
            
            return max(0, velocity)  # ç¡®ä¿éè´Ÿ
            
        except Exception as e:
            print(f"è®¡ç®—åº“å­˜å‘¨è½¬ç‡æ—¶å‡ºé”™: {e}")
            return 0.0
    
    def calculate_trend_strength(self, df: pd.DataFrame, window: int = 30) -> float:
        """è®¡ç®—è¶‹åŠ¿å¼ºåº¦"""
        try:
            if len(df) < window:
                window = max(5, len(df) // 2)  # è°ƒæ•´çª—å£å¤§å°
            
            if len(df) < 5:
                return 0.0
            
            price_change = df['åº“å­˜'].diff().dropna()
            if len(price_change) < 5:
                return 0.0
            
            # ä½¿ç”¨æ›´ç¨³å¥çš„æ–¹æ³•è®¡ç®—è¶‹åŠ¿å¼ºåº¦
            positive_changes = price_change[price_change > 0]
            negative_changes = price_change[price_change < 0]
            
            if len(positive_changes) == 0 and len(negative_changes) == 0:
                return 0.0
            
            # è®¡ç®—æ­£è´Ÿå˜åŒ–çš„æ€»å’Œ
            positive_sum = positive_changes.sum() if len(positive_changes) > 0 else 0
            negative_sum = abs(negative_changes.sum()) if len(negative_changes) > 0 else 0
            
            total_change = positive_sum + negative_sum
            if total_change == 0:
                return 0.0
            
            # è¶‹åŠ¿å¼ºåº¦ = |æ­£å˜åŒ– - è´Ÿå˜åŒ–| / æ€»å˜åŒ–
            trend_strength = abs(positive_sum - negative_sum) / total_change
            
            # ç¡®ä¿ç»“æœä¸æ˜¯nan
            if pd.isna(trend_strength):
                return 0.0
            
            return min(1.0, trend_strength)  # é™åˆ¶åœ¨0-1ä¹‹é—´
        
        except Exception as e:
            print(f"è®¡ç®—è¶‹åŠ¿å¼ºåº¦æ—¶å‡ºé”™: {e}")
            return 0.0
    
    def calculate_dynamic_threshold(self, df: pd.DataFrame, window: int = 60) -> float:
        """è®¡ç®—åŠ¨æ€é˜ˆå€¼"""
        try:
            if len(df) < 5:  # æ•°æ®å¤ªå°‘æ—¶è¿”å›é»˜è®¤å€¼
                return 5.0
            
            volatility = df['å¢å‡'].rolling(window=min(window, len(df))).std().iloc[-1]
            if pd.isna(volatility) or volatility == 0:
                return 5.0
            
            return volatility * stats.norm.ppf(self.confidence_level)
        except:
            return 5.0
    
    def analyze_inventory_trend(self, df: pd.DataFrame, category: str) -> Dict:
        """ç»¼åˆåˆ†æåº“å­˜è¶‹åŠ¿"""
        try:
            if len(df) < 5:  # æ•°æ®å¤ªå°‘
                return {
                    'è¶‹åŠ¿': 'ç¨³å®š',
                    'å˜åŒ–ç‡': 0,
                    'å¹³å‡æ—¥å˜åŒ–': 0,
                    'è¶‹åŠ¿å¼ºåº¦': 0,
                    'ä¿¡å·å¼ºåº¦': 0,
                    'åº“å­˜å‘¨è½¬ç‡': 0,
                    'å­£èŠ‚æ€§å› å­': 0,
                    'åŠ¨æ€é˜ˆå€¼': 0
                }
            
            recent_data = df.tail(min(30, len(df)))
            total_change = recent_data['å¢å‡'].sum()
            avg_change = total_change / len(recent_data)
            
            # ä¼˜åŒ–å˜åŒ–ç‡è®¡ç®—
            start_inventory = recent_data['åº“å­˜'].iloc[0]
            end_inventory = recent_data['åº“å­˜'].iloc[-1]
            
            # æ›´ç¨³å¥çš„å˜åŒ–ç‡è®¡ç®—
            if start_inventory > 0:
                change_rate = (end_inventory - start_inventory) / start_inventory * 100
                # å¯¹äºæç«¯å€¼è¿›è¡Œåˆç†é™åˆ¶
                if abs(change_rate) > 200:
                    # ä½¿ç”¨å¹³å‡åº“å­˜ä½œä¸ºåŸºå‡†é‡æ–°è®¡ç®—
                    avg_inventory = recent_data['åº“å­˜'].mean()
                    if avg_inventory > 0:
                        change_rate = (end_inventory - start_inventory) / avg_inventory * 100
                    else:
                        change_rate = 0
            else:
                # èµ·å§‹åº“å­˜ä¸º0æ—¶ï¼Œä½¿ç”¨ä¸åŒçš„è®¡ç®—æ–¹æ³•
                if end_inventory > 0:
                    change_rate = 100
                else:
                    change_rate = 0
            
            # é™åˆ¶å˜åŒ–ç‡èŒƒå›´åˆ°åˆç†åŒºé—´
            change_rate = min(max(change_rate, -150), 150)
            
            # è®¡ç®—å…¶ä»–æŒ‡æ ‡
            seasonal_factor = self.calculate_seasonal_factor(df, category)
            inventory_velocity = self.calculate_inventory_velocity(df)
            trend_strength = self.calculate_trend_strength(df)
            dynamic_threshold = self.calculate_dynamic_threshold(df)
            
            # è¶‹åŠ¿åˆ¤æ–­ - ä½¿ç”¨å›ºå®šçš„ç§‘å­¦é˜ˆå€¼
            trend = 'ç¨³å®š'
            if abs(change_rate) > 10:  # å›ºå®š10%é˜ˆå€¼
                if change_rate > 10 and avg_change > 0:
                    trend = 'ç´¯åº“'
                elif change_rate < -10 and avg_change < 0:
                    trend = 'å»åº“'
            elif abs(change_rate) > 5:  # æ¬¡çº§é˜ˆå€¼5%
                if change_rate > 5 and avg_change > 0 and trend_strength > 0.2:
                    trend = 'ç´¯åº“'
                elif change_rate < -5 and avg_change < 0 and trend_strength > 0.2:
                    trend = 'å»åº“'
            
            # ä¿¡å·å¼ºåº¦è®¡ç®— - ä¿®å¤nané—®é¢˜
            try:
                if dynamic_threshold > 0:
                    signal_strength = min(abs(change_rate) / max(dynamic_threshold, 1), 1.0)
                else:
                    signal_strength = min(abs(change_rate) / 10, 1.0)  # ä½¿ç”¨å›ºå®šé˜ˆå€¼
                
                # ç¡®ä¿ä¿¡å·å¼ºåº¦ä¸æ˜¯nan
                if pd.isna(signal_strength):
                    signal_strength = abs(change_rate) / 100  # ç®€å•è®¡ç®—
                    
                signal_strength = max(0, min(1, signal_strength))  # é™åˆ¶åœ¨0-1ä¹‹é—´
            except:
                signal_strength = abs(change_rate) / 100
                signal_strength = max(0, min(1, signal_strength))
            
            return {
                'è¶‹åŠ¿': trend,
                'å˜åŒ–ç‡': change_rate,
                'å¹³å‡æ—¥å˜åŒ–': avg_change,
                'è¶‹åŠ¿å¼ºåº¦': trend_strength if not pd.isna(trend_strength) else 0,
                'ä¿¡å·å¼ºåº¦': signal_strength,
                'åº“å­˜å‘¨è½¬ç‡': inventory_velocity if not pd.isna(inventory_velocity) else 0,
                'å­£èŠ‚æ€§å› å­': seasonal_factor.iloc[-1] if not seasonal_factor.empty and not pd.isna(seasonal_factor.iloc[-1]) else 0,
                'åŠ¨æ€é˜ˆå€¼': dynamic_threshold
            }
        except Exception as e:
            print(f"åˆ†æè¶‹åŠ¿æ—¶å‡ºé”™: {e}")
            return {
                'è¶‹åŠ¿': 'ç¨³å®š',
                'å˜åŒ–ç‡': 0,
                'å¹³å‡æ—¥å˜åŒ–': 0,
                'è¶‹åŠ¿å¼ºåº¦': 0,
                'ä¿¡å·å¼ºåº¦': 0,
                'åº“å­˜å‘¨è½¬ç‡': 0,
                'å­£èŠ‚æ€§å› å­': 0,
                'åŠ¨æ€é˜ˆå€¼': 0
            }

def get_futures_category(symbol: str) -> str:
    """è·å–æœŸè´§å“ç§åˆ†ç±»"""
    categories = {
        'å†œäº§å“': ['è±†ä¸€', 'è±†äºŒ', 'è±†ç²•', 'è±†æ²¹', 'ç‰ç±³', 'ç‰ç±³æ·€ç²‰', 'èœç²•', 'èœæ²¹', 'æ£•æ¦ˆ', 'ç™½ç³–', 'æ£‰èŠ±', 'è‹¹æœ', 'é¸¡è›‹', 'ç”ŸçŒª', 'çº¢æ£', 'èŠ±ç”Ÿ'],
        'å·¥ä¸šå“': ['èºçº¹é’¢', 'çƒ­å·', 'é“çŸ¿çŸ³', 'ç„¦ç…¤', 'ç„¦ç‚­', 'ä¸é”ˆé’¢', 'æ²ªé“œ', 'æ²ªé“', 'æ²ªé”Œ', 'æ²ªé“…', 'æ²ªé•', 'æ²ªé”¡', 'æ²ªé“¶', 'æ²ªé‡‘'],
        'èƒ½æºåŒ–å·¥': ['åŸæ²¹', 'ç‡ƒæ²¹', 'æ²¥é’', 'PTA', 'ç”²é†‡', 'ä¹™äºŒé†‡', 'PVC', 'PP', 'å¡‘æ–™', 'æ©¡èƒ¶', '20å·èƒ¶', 'è‹¯ä¹™çƒ¯', 'æ¶²åŒ–çŸ³æ²¹æ°”', 'ä½ç¡«ç‡ƒæ–™æ²¹']
    }
    
    for category, symbols in categories.items():
        if symbol in symbols:
            return category
    return 'å…¶ä»–'

def get_single_inventory_data_streamlit(symbol: str, end_date=None, days_back=30) -> Optional[pd.DataFrame]:
    """è·å–å•ä¸ªæœŸè´§å“ç§çš„åº“å­˜æ•°æ®ï¼ˆStreamlitç‰ˆæœ¬ï¼‰"""
    try:
        df = cached_futures_inventory_em(symbol)
        
        if df is not None and not df.empty and 'æ—¥æœŸ' in df.columns and 'åº“å­˜' in df.columns:
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
            df = df.sort_values('æ—¥æœŸ')
            
            # å¦‚æœæŒ‡å®šäº†æ—¥æœŸèŒƒå›´ï¼Œè¿›è¡Œç­›é€‰
            if end_date is not None:
                if isinstance(end_date, str):
                    end_date = pd.to_datetime(end_date).date()
                elif hasattr(end_date, 'date'):
                    end_date = end_date.date()
                
                # è®¡ç®—å¼€å§‹æ—¥æœŸ
                start_date = end_date - timedelta(days=days_back)
                
                # ç­›é€‰æ—¥æœŸèŒƒå›´
                df = df[
                    (df['æ—¥æœŸ'].dt.date >= start_date) & 
                    (df['æ—¥æœŸ'].dt.date <= end_date)
                ]
            
            if len(df) > 0:
                df['å¢å‡'] = df['åº“å­˜'].diff().fillna(0)
                return df
            else:
                return None
        else:
            return None
    except Exception:
        return None

def run_inventory_analysis(selected_symbols: List[str], confidence_level: float = 0.95, 
                          progress_callback=None, end_date=None, days_back=30) -> Tuple[pd.DataFrame, Dict, Dict]:
    """è¿è¡Œåº“å­˜åˆ†æ"""
    
    # ç”Ÿæˆåˆ†æIDï¼ˆåŒ…å«æ—¥æœŸå‚æ•°ï¼‰
    analysis_id = get_analysis_id(
        'inventory', 
        symbols=selected_symbols, 
        confidence_level=confidence_level,
        end_date=str(end_date) if end_date else None,
        days_back=days_back
    )
    
    # æ£€æŸ¥ç¼“å­˜
    cached_result = get_cached_analysis_result(analysis_id)
    if cached_result is not None:
        return cached_result['results_df'], cached_result['inventory_trends'], cached_result['data_dict']
    
    # è·å–æ•°æ®
    data_dict = {}
    total_symbols = len(selected_symbols)
    
    for i, symbol in enumerate(selected_symbols):
        if progress_callback:
            progress_callback(i + 1, total_symbols, f"æ­£åœ¨è·å– {symbol} çš„åº“å­˜æ•°æ®")
        
        df = get_single_inventory_data_streamlit(symbol, end_date, days_back)
        if df is not None:
            data_dict[symbol] = df
        
        time.sleep(0.05)  # é¿å…è¯·æ±‚è¿‡å¿«
    
    if not data_dict:
        return pd.DataFrame(), {}, {}
    
    # åˆ†ææ•°æ®
    analyzer = FuturesInventoryAnalyzer(confidence_level)
    results = []
    inventory_trends = {'ç´¯åº“å“ç§': [], 'å»åº“å“ç§': [], 'åº“å­˜ç¨³å®šå“ç§': []}
    
    for symbol, df in data_dict.items():
        try:
            category = get_futures_category(symbol)
            analysis = analyzer.analyze_inventory_trend(df, category)
            
            results.append({
                'å“ç§': symbol,
                'åˆ†ç±»': category,
                **analysis
            })
            
            trend = analysis['è¶‹åŠ¿']
            if trend == 'ç´¯åº“':
                inventory_trends['ç´¯åº“å“ç§'].append(symbol)
            elif trend == 'å»åº“':
                inventory_trends['å»åº“å“ç§'].append(symbol)
            else:
                inventory_trends['åº“å­˜ç¨³å®šå“ç§'].append(symbol)
                
        except Exception as e:
            st.warning(f"åˆ†æ {symbol} æ—¶å‡ºé”™: {str(e)}")
    
    if not results:
        return pd.DataFrame(), {}, {}
    
    results_df = pd.DataFrame(results)
    results_df = results_df.sort_values('ä¿¡å·å¼ºåº¦', ascending=False)
    
    # ç¼“å­˜ç»“æœ
    result_to_cache = {
        'results_df': results_df,
        'inventory_trends': inventory_trends,
        'data_dict': data_dict
    }
    cache_analysis_result(analysis_id, result_to_cache)
    
    return results_df, inventory_trends, data_dict

def get_futures_price_data(symbol: str) -> Optional[pd.DataFrame]:
    """è·å–æœŸè´§ä»·æ ¼æ•°æ® - æ”¹è¿›ç‰ˆæœ¬ï¼Œæ”¯æŒå¤šç§åˆçº¦åç§°æ ¼å¼"""
    
    # æœŸè´§åˆçº¦åç§°æ˜ å°„è¡¨ - ä½¿ç”¨æ­£ç¡®çš„æ ¼å¼
    symbol_mapping = {
        'é•': ['NI0', 'é•è¿ç»­', 'NIè¿ç»­'],
        'æ²ªé“œ': ['CU0', 'æ²ªé“œè¿ç»­', 'CUè¿ç»­'],
        'é”¡': ['SN0', 'é”¡è¿ç»­', 'SNè¿ç»­'],
        'æ²ªé“': ['AL0', 'æ²ªé“è¿ç»­', 'ALè¿ç»­'],
        'è‹¯ä¹™çƒ¯': ['EB0', 'è‹¯ä¹™çƒ¯è¿ç»­', 'EBè¿ç»­'],
        'æ¶²åŒ–çŸ³æ²¹æ°”': ['PG0', 'æ¶²åŒ–çŸ³æ²¹æ°”è¿ç»­', 'PGè¿ç»­'],
        'ä½ç¡«ç‡ƒæ–™æ²¹': ['LU0', 'ä½ç¡«ç‡ƒæ–™æ²¹è¿ç»­', 'LUè¿ç»­'],
        'å¤šæ™¶ç¡…': ['OQ0', 'å¤šæ™¶ç¡…è¿ç»­', 'OQè¿ç»­'],
        'ç¡…é“': ['SF0', 'ç¡…é“è¿ç»­', 'SFè¿ç»­'],
        'åŸæœ¨': ['WO0', 'åŸæœ¨è¿ç»­', 'WOè¿ç»­'],
        'é“çŸ¿çŸ³': ['I0', 'é“çŸ¿çŸ³è¿ç»­', 'Iè¿ç»­'],
        'èºçº¹é’¢': ['RB0', 'èºçº¹é’¢è¿ç»­', 'RBè¿ç»­'],
        'çƒ­å·': ['HC0', 'çƒ­å·è¿ç»­', 'HCè¿ç»­'],
        'ç„¦ç…¤': ['JM0', 'ç„¦ç…¤è¿ç»­', 'JMè¿ç»­'],
        'ç„¦ç‚­': ['J0', 'ç„¦ç‚­è¿ç»­', 'Jè¿ç»­'],
        'è±†ä¸€': ['A0', 'è±†ä¸€è¿ç»­', 'Aè¿ç»­'],
        'è±†äºŒ': ['B0', 'è±†äºŒè¿ç»­', 'Bè¿ç»­'],
        'è±†ç²•': ['M0', 'è±†ç²•è¿ç»­', 'Mè¿ç»­'],
        'è±†æ²¹': ['Y0', 'è±†æ²¹è¿ç»­', 'Yè¿ç»­'],
        'ç‰ç±³': ['C0', 'ç‰ç±³è¿ç»­', 'Cè¿ç»­'],
        'ç‰ç±³æ·€ç²‰': ['CS0', 'ç‰ç±³æ·€ç²‰è¿ç»­', 'CSè¿ç»­'],
        'èœç²•': ['RM0', 'èœç²•è¿ç»­', 'RMè¿ç»­'],
        'èœæ²¹': ['OI0', 'èœæ²¹è¿ç»­', 'OIè¿ç»­'],
        'æ£•æ¦ˆ': ['P0', 'æ£•æ¦ˆè¿ç»­', 'Pè¿ç»­'],
        'ç™½ç³–': ['SR0', 'ç™½ç³–è¿ç»­', 'SRè¿ç»­'],
        'æ£‰èŠ±': ['CF0', 'æ£‰èŠ±è¿ç»­', 'CFè¿ç»­'],
        'éƒ‘æ£‰': ['CF0', 'éƒ‘æ£‰è¿ç»­', 'CFè¿ç»­'],
        'è‹¹æœ': ['AP0', 'è‹¹æœè¿ç»­', 'APè¿ç»­'],
        'é¸¡è›‹': ['JD0', 'é¸¡è›‹è¿ç»­', 'JDè¿ç»­'],
        'ç”ŸçŒª': ['LH0', 'ç”ŸçŒªè¿ç»­', 'LHè¿ç»­'],
        'çº¢æ£': ['CJ0', 'çº¢æ£è¿ç»­', 'CJè¿ç»­'],
        'èŠ±ç”Ÿ': ['PK0', 'èŠ±ç”Ÿè¿ç»­', 'PKè¿ç»­'],
        'PTA': ['TA0', 'PTAè¿ç»­', 'TAè¿ç»­'],
        'ç”²é†‡': ['MA0', 'ç”²é†‡è¿ç»­', 'MAè¿ç»­'],
        'ä¹™äºŒé†‡': ['EG0', 'ä¹™äºŒé†‡è¿ç»­', 'EGè¿ç»­'],
        'PVC': ['V0', 'PVCè¿ç»­', 'Vè¿ç»­'],
        'PP': ['PP0', 'PPè¿ç»­'],
        'èšä¸™çƒ¯': ['PP0', 'èšä¸™çƒ¯è¿ç»­', 'PPè¿ç»­'],
        'å¡‘æ–™': ['L0', 'å¡‘æ–™è¿ç»­', 'Lè¿ç»­'],
        'æ©¡èƒ¶': ['RU0', 'æ©¡èƒ¶è¿ç»­', 'RUè¿ç»­'],
        '20å·èƒ¶': ['NR0', '20å·èƒ¶è¿ç»­', 'NRè¿ç»­'],
        'æ²¥é’': ['BU0', 'æ²¥é’è¿ç»­', 'BUè¿ç»­'],
        'ç‡ƒæ²¹': ['FU0', 'ç‡ƒæ²¹è¿ç»­', 'FUè¿ç»­'],
        'åŸæ²¹': ['SC0', 'åŸæ²¹è¿ç»­', 'SCè¿ç»­'],
        'çº¯ç¢±': ['SA0', 'çº¯ç¢±è¿ç»­', 'SAè¿ç»­'],
        'ç»ç’ƒ': ['FG0', 'ç»ç’ƒè¿ç»­', 'FGè¿ç»­'],
        'å°¿ç´ ': ['UR0', 'å°¿ç´ è¿ç»­', 'URè¿ç»­'],
        'çŸ­çº¤': ['PF0', 'çŸ­çº¤è¿ç»­', 'PFè¿ç»­'],
        'çº¸æµ†': ['SP0', 'çº¸æµ†è¿ç»­', 'SPè¿ç»­'],
        'ä¸é”ˆé’¢': ['SS0', 'ä¸é”ˆé’¢è¿ç»­', 'SSè¿ç»­'],
        'æ²ªé”Œ': ['ZN0', 'æ²ªé”Œè¿ç»­', 'ZNè¿ç»­'],
        'æ²ªé“…': ['PB0', 'æ²ªé“…è¿ç»­', 'PBè¿ç»­'],
        'æ²ªé•': ['NI0', 'æ²ªé•è¿ç»­', 'NIè¿ç»­'],
        'æ²ªé“¶': ['AG0', 'æ²ªé“¶è¿ç»­', 'AGè¿ç»­'],
        'æ²ªé‡‘': ['AU0', 'æ²ªé‡‘è¿ç»­', 'AUè¿ç»­'],
        'é”°ç¡…': ['SM0', 'é”°ç¡…è¿ç»­', 'SMè¿ç»­'],
        'æ°§åŒ–é“': ['AO0', 'æ°§åŒ–é“è¿ç»­', 'AOè¿ç»­'],
        'ç¢³é…¸é”‚': ['LC0', 'ç¢³é…¸é”‚è¿ç»­', 'LCè¿ç»­'],
        'å·¥ä¸šç¡…': ['SI0', 'å·¥ä¸šç¡…è¿ç»­', 'SIè¿ç»­'],
        'çƒ§ç¢±': ['SH0', 'çƒ§ç¢±è¿ç»­', 'SHè¿ç»­'],
        'å¯¹äºŒç”²è‹¯': ['PX0', 'å¯¹äºŒç”²è‹¯è¿ç»­', 'PXè¿ç»­'],
        'ç“¶ç‰‡': ['BP0', 'ç“¶ç‰‡è¿ç»­', 'BPè¿ç»­'],
        'ä¸äºŒçƒ¯æ©¡èƒ¶': ['BR0', 'ä¸äºŒçƒ¯æ©¡èƒ¶è¿ç»­', 'BRè¿ç»­'],
        'æ£‰çº±': ['CY0', 'æ£‰çº±è¿ç»­', 'CYè¿ç»­']
    }
    
    # è·å–å¯èƒ½çš„åˆçº¦åç§°åˆ—è¡¨
    possible_names = symbol_mapping.get(symbol, [f"{symbol}0", f"{symbol}è¿ç»­"])
    
    # å°è¯•ä¸åŒçš„åˆçº¦åç§°
    for contract_name in possible_names:
        try:
            df = cached_futures_hist_em(contract_name)
            if df is not None and not df.empty and 'æ”¶ç›˜' in df.columns:
                return df
        except Exception:
            continue
    
    # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›None
    return None

def align_inventory_and_price_data(inventory_df: pd.DataFrame, price_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """å¯¹é½åº“å­˜å’Œä»·æ ¼æ•°æ®çš„æ—¶é—´èŒƒå›´ - æ”¹è¿›ç‰ˆæœ¬"""
    # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
    if inventory_df['æ—¥æœŸ'].dtype != 'datetime64[ns]':
        inventory_df['æ—¥æœŸ'] = pd.to_datetime(inventory_df['æ—¥æœŸ'])
    if price_df['æ—¥æœŸ'].dtype != 'datetime64[ns]':
        price_df['æ—¥æœŸ'] = pd.to_datetime(price_df['æ—¥æœŸ'])
    
    # æ‰¾åˆ°æ—¶é—´èŒƒå›´
    inventory_start = inventory_df['æ—¥æœŸ'].min()
    inventory_end = inventory_df['æ—¥æœŸ'].max()
    price_start = price_df['æ—¥æœŸ'].min()
    price_end = price_df['æ—¥æœŸ'].max()
    
    # è®¡ç®—é‡å èŒƒå›´
    common_start = max(inventory_start, price_start)
    common_end = min(inventory_end, price_end)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é‡å 
    if common_start > common_end:
        # æ²¡æœ‰é‡å ï¼Œå°è¯•æ›´å®½æ¾çš„åŒ¹é…
        # ä½¿ç”¨è¾ƒå¤§çš„æ—¶é—´èŒƒå›´ï¼Œå…è®¸éƒ¨åˆ†æ•°æ®ç¼ºå¤±
        extended_start = min(inventory_start, price_start)
        extended_end = max(inventory_end, price_end)
        
        # ç­›é€‰æ•°æ® - ä½¿ç”¨æ›´å®½æ¾çš„æ¡ä»¶
        aligned_inventory = inventory_df[
            (inventory_df['æ—¥æœŸ'] >= extended_start) & 
            (inventory_df['æ—¥æœŸ'] <= extended_end)
        ].copy()
        
        aligned_price = price_df[
            (price_df['æ—¥æœŸ'] >= extended_start) & 
            (price_df['æ—¥æœŸ'] <= extended_end)
        ].copy()
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ•°æ®ï¼Œè¿”å›åŸå§‹æ•°æ®çš„æœ€è¿‘éƒ¨åˆ†
        if len(aligned_inventory) == 0:
            aligned_inventory = inventory_df.tail(min(100, len(inventory_df))).copy()
        if len(aligned_price) == 0:
            aligned_price = price_df.tail(min(100, len(price_df))).copy()
            
    else:
        # æœ‰é‡å ï¼Œä½¿ç”¨äº¤é›†
        aligned_inventory = inventory_df[
            (inventory_df['æ—¥æœŸ'] >= common_start) & 
            (inventory_df['æ—¥æœŸ'] <= common_end)
        ].copy()
        
        aligned_price = price_df[
            (price_df['æ—¥æœŸ'] >= common_start) & 
            (price_df['æ—¥æœŸ'] <= common_end)
        ].copy()
    
    return aligned_inventory, aligned_price

def create_plotly_trend_chart(df: pd.DataFrame, symbol: str, analysis_result: Dict):
    """åˆ›å»ºåº“å­˜è¶‹åŠ¿å›¾"""
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=(f'{symbol} åº“å­˜èµ°åŠ¿', 'åº“å­˜å˜åŒ–é‡'),
        vertical_spacing=0.1
    )
    
    # åº“å­˜èµ°åŠ¿
    fig.add_trace(
        go.Scatter(
            x=df['æ—¥æœŸ'],
            y=df['åº“å­˜'],
            mode='lines+markers',
            name='åº“å­˜',
            line=dict(color='blue', width=2)
        ),
        row=1, col=1
    )
    
    # åº“å­˜å˜åŒ–é‡
    colors = ['red' if x < 0 else 'green' for x in df['å¢å‡']]
    fig.add_trace(
        go.Bar(
            x=df['æ—¥æœŸ'],
            y=df['å¢å‡'],
            name='åº“å­˜å˜åŒ–',
            marker_color=colors
        ),
        row=2, col=1
    )
    
    fig.update_layout(
        height=600,
        title_text=f"{symbol} åº“å­˜åˆ†æ - è¶‹åŠ¿: {analysis_result['è¶‹åŠ¿']}",
        showlegend=True
    )
    
    return fig

def create_plotly_inventory_price_chart(inventory_df: pd.DataFrame, price_df: pd.DataFrame, 
                                       symbol: str, analysis_result: Dict):
    """åˆ›å»ºåº“å­˜ä»·æ ¼å¯¹æ¯”å›¾ - åŒYè½´æ˜¾ç¤º"""
    # åˆ›å»ºåŒYè½´å­å›¾
    fig = make_subplots(
        rows=1, cols=1,
        specs=[[{"secondary_y": True}]],
        subplot_titles=[f'{symbol} åº“å­˜ä¸ä»·æ ¼èµ°åŠ¿å¯¹æ¯”']
    )
    
    # æ·»åŠ ä»·æ ¼èµ°åŠ¿ï¼ˆä¸»Yè½´ï¼‰
    fig.add_trace(
        go.Scatter(
            x=price_df['æ—¥æœŸ'],
            y=price_df['æ”¶ç›˜'],
            mode='lines',
            name='æœŸè´§ä»·æ ¼',
            line=dict(color='red', width=2),
            yaxis='y'
        ),
        secondary_y=False
    )
    
    # æ·»åŠ åº“å­˜èµ°åŠ¿ï¼ˆæ¬¡Yè½´ï¼‰
    fig.add_trace(
        go.Scatter(
            x=inventory_df['æ—¥æœŸ'],
            y=inventory_df['åº“å­˜'],
            mode='lines+markers',
            name='åº“å­˜',
            line=dict(color='blue', width=2),
            marker=dict(size=4),
            yaxis='y2'
        ),
        secondary_y=True
    )
    
    # è®¾ç½®Yè½´æ ‡ç­¾
    fig.update_yaxes(title_text="æœŸè´§ä»·æ ¼", secondary_y=False, side="left")
    fig.update_yaxes(title_text="åº“å­˜", secondary_y=True, side="right")
    
    # è®¾ç½®Xè½´æ ‡ç­¾
    fig.update_xaxes(title_text="æ—¥æœŸ")
    
    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        height=600,
        title_text=f"{symbol} åº“å­˜ä¸ä»·æ ¼èµ°åŠ¿å¯¹æ¯”åˆ†æ - è¶‹åŠ¿: {analysis_result['è¶‹åŠ¿']}",
        showlegend=True,
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    return fig

def create_summary_charts(results_df: pd.DataFrame, inventory_trends: Dict):
    """åˆ›å»ºæ±‡æ€»å›¾è¡¨"""
    col1, col2 = st.columns(2)
    
    with col1:
        # è¶‹åŠ¿åˆ†å¸ƒé¥¼å›¾
        trend_counts = results_df['è¶‹åŠ¿'].value_counts()
        fig = px.pie(
            values=trend_counts.values,
            names=trend_counts.index,
            title="åº“å­˜è¶‹åŠ¿åˆ†å¸ƒ",
            color_discrete_map={
                'ç´¯åº“': '#ff6b6b',
                'å»åº“': '#51cf66',
                'ç¨³å®š': '#74c0fc'
            }
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ä¿¡å·å¼ºåº¦åˆ†å¸ƒ
        fig = px.histogram(
            results_df,
            x='ä¿¡å·å¼ºåº¦',
            title="ä¿¡å·å¼ºåº¦åˆ†å¸ƒ",
            nbins=20,
            color_discrete_sequence=['#339af0']
        )
        st.plotly_chart(fig, use_container_width=True)

def show_basis_detailed_chart(df, opportunity):
    """æ˜¾ç¤ºåŸºå·®è¯¦ç»†åˆ†æå›¾è¡¨"""
    st.subheader(f"ğŸ“Š {opportunity.name} è¯¦ç»†åˆ†æ")
    
    # åˆ›å»ºå››ä¸ªå­å›¾
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('ä»·æ ¼èµ°åŠ¿', 'åŸºå·®åˆ†æ', 'åŸºå·®åˆ†å¸ƒ', 'æŠ€æœ¯æŒ‡æ ‡'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": True}]]
    )
    
    # 1. ä»·æ ¼èµ°åŠ¿å›¾
    fig.add_trace(
        go.Scatter(x=df['date'], y=df['spot_price'], name='ç°è´§ä»·æ ¼', line=dict(color='blue')),
        row=1, col=1
    )
    fig.add_trace(
        go.Scatter(x=df['date'], y=df['dominant_contract_price'], name='æœŸè´§ä»·æ ¼', line=dict(color='red')),
        row=1, col=1
    )
    
    # 2. åŸºå·®åˆ†æ
    fig.add_trace(
        go.Scatter(x=df['date'], y=df['basis'], name='åŸºå·®', line=dict(color='green')),
        row=1, col=2
    )
    fig.add_trace(
        go.Scatter(x=df['date'], y=df['basis_ma10'], name='åŸºå·®MA10', line=dict(color='orange', dash='dash')),
        row=1, col=2
    )
    
    # 3. åŸºå·®åˆ†å¸ƒç›´æ–¹å›¾
    fig.add_trace(
        go.Histogram(x=df['basis'], name='åŸºå·®åˆ†å¸ƒ', nbinsx=20),
        row=2, col=1
    )
    
    # 4. RSIæŒ‡æ ‡
    fig.add_trace(
        go.Scatter(x=df['date'], y=df['basis_rsi'], name='åŸºå·®RSI', line=dict(color='purple')),
        row=2, col=2
    )
    
    # æ·»åŠ RSIå‚è€ƒçº¿
    fig.add_hline(y=70, line_dash="dot", line_color="red", row=2, col=2)
    fig.add_hline(y=30, line_dash="dot", line_color="green", row=2, col=2)
    
    fig.update_layout(height=800, showlegend=True, title_text=f"{opportunity.name} åŸºå·®åˆ†æè¯¦æƒ…")
    st.plotly_chart(fig, use_container_width=True)
    
    # æŠ•èµ„å»ºè®®
    st.subheader("ğŸ’¡ æŠ•èµ„å»ºè®®")
    col1, col2 = st.columns(2)
    
    with col1:
        st.info(f"""
        **æœºä¼šç±»å‹**: {opportunity.opportunity_type}
        **ç½®ä¿¡åº¦**: {opportunity.confidence:.1f}%
        **é¢„æœŸæ”¶ç›Š**: {opportunity.expected_return:.1f}%
        **å»ºè®®æŒä»“(å¤©)**: {opportunity.holding_period}å¤©
        """)
    
    with col2:
        st.warning(f"""
        **é£é™©ç­‰çº§**: {opportunity.risk_level}
        **Z-Score**: {opportunity.z_score:.2f}
        **å½“å‰åŸºå·®**: {opportunity.current_basis:.2f}
        **å†å²å‡å€¼**: {opportunity.basis_mean:.2f}
        """)
    
    # æ“ä½œè¯´æ˜
    if "ä¹°åŸºå·®" in opportunity.opportunity_type:
        st.success("ğŸ“ˆ **ä¹°åŸºå·®æ“ä½œ**: ä¹°å…¥ç°è´§ + å–å‡ºæœŸè´§ï¼ˆç±»ä¼¼åšç©ºæœŸè´§ï¼‰")
    else:
        st.error("ğŸ“‰ **å–åŸºå·®æ“ä½œ**: å–å‡ºç°è´§ + ä¹°å…¥æœŸè´§ï¼ˆç±»ä¼¼åšå¤šæœŸè´§ï¼‰")

# ==================== é¡µé¢å‡½æ•° ====================

def inventory_analysis_page():
    """åº“å­˜åˆ†æé¡µé¢"""
    st.header("ğŸ“ˆ æœŸè´§åº“å­˜åˆ†æ")
    
    # å‚æ•°è®¾ç½®
    st.subheader("ğŸ”§ åˆ†æå‚æ•°è®¾ç½®")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # æœŸè´§å“ç§é€‰æ‹©
        all_symbols = [
            "æ²ªé“œ", "é•", "é”¡", "æ²ªé“", "è‹¯ä¹™çƒ¯", "æ¶²åŒ–çŸ³æ²¹æ°”", "ä½ç¡«ç‡ƒæ–™æ²¹", "æ£‰çº±",
            "ä¸é”ˆé’¢", "çŸ­çº¤", "æ²ªé“…", "å¤šæ™¶ç¡…", "ä¸äºŒçƒ¯æ©¡èƒ¶", "æ²ªé”Œ", "ç¡…é“", "é¸¡è›‹",
            "ç“¶ç‰‡", "å·¥ä¸šç¡…", "æ²¥é’", "20å·èƒ¶", "åŸæœ¨", "è±†ä¸€", "ç‰ç±³", "ç‡ƒæ²¹",
            "èœç±½", "ç¢³é…¸é”‚", "çº¸æµ†", "ç‰ç±³æ·€ç²‰", "æ²ªé“¶", "æ²ªé‡‘", "å¡‘æ–™", "èšä¸™çƒ¯",
            "é“çŸ¿çŸ³", "è±†äºŒ", "è±†ç²•", "æ£•æ¦ˆ", "ç»ç’ƒ", "è±†æ²¹", "æ©¡èƒ¶", "çƒ§ç¢±",
            "èœç²•", "PTA", "çº¯ç¢±", "å¯¹äºŒç”²è‹¯", "èœæ²¹", "ç”ŸçŒª", "å°¿ç´ ", "PVC",
            "ä¹™äºŒé†‡", "æ°§åŒ–é“", "ç„¦ç‚­", "éƒ‘æ£‰", "ç”²é†‡", "ç™½ç³–", "é”°ç¡…", "ç„¦ç…¤",
            "çº¢æ£", "èºçº¹é’¢", "èŠ±ç”Ÿ", "è‹¹æœ", "çƒ­å·"
        ]
        
        analysis_mode = st.selectbox(
            "é€‰æ‹©åˆ†ææ¨¡å¼",
            ["å…¨å“ç§åˆ†æ", "è‡ªå®šä¹‰å“ç§åˆ†æ", "å•å“ç§è¯¦ç»†åˆ†æ"]
        )
    
    with col2:
        # æ—¥æœŸé€‰æ‹©
        end_date = st.date_input(
            "åˆ†ææˆªæ­¢æ—¥æœŸ", 
            value=datetime.now().date(),
            help="é€‰æ‹©åº“å­˜æ•°æ®çš„æˆªæ­¢æ—¥æœŸ"
        )
        
        days_back = st.slider(
            "åˆ†æå¤©æ•°", 
            min_value=15, 
            max_value=90, 
            value=30,
            help="ä»æˆªæ­¢æ—¥æœŸå¾€å‰åˆ†æçš„å¤©æ•°"
        )
    
    with col3:
        # æ’åºæ–¹å¼é€‰æ‹©
        sort_method = st.selectbox(
            "æ’åºæ–¹å¼",
            ["ä¿¡å·å¼ºåº¦", "å˜åŒ–ç‡ç»å¯¹å€¼", "è¶‹åŠ¿å¼ºåº¦"],
            help="é€‰æ‹©è¯¦ç»†åˆ†æç»“æœçš„æ’åºä¾æ®"
        )
        
        # æ’åºè¯´æ˜ - ç§»åˆ°è¿™é‡Œ
        with st.expander("ğŸ“Š æ’åºæ–¹å¼è¯´æ˜"):
            st.markdown(f"""
            **å½“å‰æ’åºæ–¹å¼ï¼š{sort_method}**
            
            - **ä¿¡å·å¼ºåº¦**ï¼šç»¼åˆè€ƒè™‘å˜åŒ–ç‡å’Œç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œåæ˜ åº“å­˜å˜åŒ–çš„å¯é ç¨‹åº¦ï¼ˆæ¨èï¼‰
            - **å˜åŒ–ç‡ç»å¯¹å€¼**ï¼šçº¯ç²¹æŒ‰åº“å­˜å˜åŒ–å¹…åº¦æ’åºï¼Œæ•°å€¼è¶Šå¤§å˜åŒ–è¶Šæ˜æ˜¾  
            - **è¶‹åŠ¿å¼ºåº¦**ï¼šåæ˜ åº“å­˜å˜åŒ–çš„æŒç»­æ€§å’Œæ–¹å‘æ€§
            
            ğŸ’¡ **å»ºè®®**ï¼šä¿¡å·å¼ºåº¦æœ€é€‚åˆæŠ•èµ„å†³ç­–ï¼Œå› ä¸ºå®ƒè€ƒè™‘äº†ç»Ÿè®¡æ˜¾è‘—æ€§
            """)
        
        # æ˜¾ç¤ºç­›é€‰é€‰é¡¹
        show_advanced = st.checkbox("æ˜¾ç¤ºé«˜çº§ç­›é€‰", value=False)
    
    with col4:
        st.info("""
        **é»˜è®¤å‚æ•°è¯´æ˜**ï¼š
        - ç´¯åº“/å»åº“é˜ˆå€¼ï¼š10%
        - è¶‹åŠ¿å¼ºåº¦é˜ˆå€¼ï¼š0.2
        - ç½®ä¿¡æ°´å¹³ï¼š95%
        
        è¿™äº›æ˜¯ç»è¿‡ä¼˜åŒ–çš„ç§‘å­¦å‚æ•°
        """)
    
    # é«˜çº§ç­›é€‰é€‰é¡¹ï¼ˆå¯é€‰ï¼‰
    if show_advanced:
        st.subheader("ğŸ” é«˜çº§ç­›é€‰é€‰é¡¹")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            confidence_level = st.slider("ç½®ä¿¡æ°´å¹³", 0.90, 0.99, 0.95, 0.01, 
                                       help="ç»Ÿè®¡å­¦ç½®ä¿¡æ°´å¹³ï¼Œç”¨äºè®¡ç®—åŠ¨æ€é˜ˆå€¼")
        with col2:
            change_threshold = st.slider("å˜åŒ–ç‡é˜ˆå€¼ (%)", 5, 20, 10, 1,
                                       help="åˆ¤æ–­ç´¯åº“/å»åº“çš„æœ€å°å˜åŒ–ç‡")
        with col3:
            trend_threshold = st.slider("è¶‹åŠ¿å¼ºåº¦é˜ˆå€¼", 0.1, 0.8, 0.2, 0.1,
                                      help="åˆ¤æ–­è¶‹åŠ¿å¯é æ€§çš„é˜ˆå€¼")
    else:
        # ä½¿ç”¨é»˜è®¤çš„æœ€ä½³å‚æ•°
        confidence_level = 0.95
        change_threshold = 10
        trend_threshold = 0.2
    
    # å“ç§é€‰æ‹©
    if analysis_mode == "å…¨å“ç§åˆ†æ":
        selected_symbols = all_symbols
        st.info(f"å°†åˆ†æå…¨éƒ¨ {len(all_symbols)} ä¸ªå“ç§")
    elif analysis_mode == "è‡ªå®šä¹‰å“ç§åˆ†æ":
        selected_symbols = st.multiselect(
            "é€‰æ‹©è¦åˆ†æçš„å“ç§",
            all_symbols,
            default=all_symbols[:10]
        )
    else:  # å•å“ç§è¯¦ç»†åˆ†æ
        selected_symbols = [st.selectbox("é€‰æ‹©å“ç§", all_symbols)]
    
    # åˆ†ææŒ‰é’®
    col1, col2, col3, col4 = st.columns([1, 1, 1, 2])
    with col1:
        start_analysis = st.button("ğŸš€ å¼€å§‹åº“å­˜åˆ†æ", type="primary")
    with col2:
        # æ£€æŸ¥æ˜¯å¦æœ‰å·²æœ‰çš„åˆ†æç»“æœ
        has_existing_results = st.session_state.get('inventory_results') is not None
        use_existing = st.button("ğŸ“Š ä½¿ç”¨å·²æœ‰æ•°æ®", disabled=not has_existing_results)
    with col3:
        if st.button("ğŸ”„ é‡æ–°åˆ†æ"):
            # æ¸…é™¤ç¼“å­˜
            if 'inventory_results' in st.session_state:
                del st.session_state.inventory_results
            cache_manager.clear_expired()
            st.rerun()
    with col4:
        if st.button("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰ç¼“å­˜"):
            cache_manager.clear_expired()
            st.session_state.clear()
            st.success("ç¼“å­˜å·²æ¸…é™¤")
            st.rerun()
    
    # æ˜¾ç¤ºå·²æœ‰æ•°æ®ä¿¡æ¯
    if has_existing_results:
        results_df, inventory_trends, data_dict = st.session_state.inventory_results
        st.info(f"ğŸ’¾ å·²æœ‰åˆ†ææ•°æ®ï¼š{len(results_df)}ä¸ªå“ç§ï¼ŒåŒ…å«{len(inventory_trends['ç´¯åº“å“ç§'])}ä¸ªç´¯åº“å“ç§ï¼Œ{len(inventory_trends['å»åº“å“ç§'])}ä¸ªå»åº“å“ç§")
    
    # æ‰§è¡Œåˆ†æ
    if start_analysis or use_existing or st.session_state.get('inventory_results') is not None:
        if not selected_symbols:
            st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå“ç§è¿›è¡Œåˆ†æï¼")
            return
        
        # å¦‚æœæ˜¯æ–°çš„åˆ†æè¯·æ±‚ï¼Œæ‰§è¡Œåˆ†æ
        if start_analysis:
            # åˆ›å»ºè¿›åº¦æ˜¾ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            def progress_callback(current, total, message):
                progress_bar.progress(current / total)
                status_text.text(f"{message} [{current}/{total}]")
            
            with st.spinner(f"æ­£åœ¨åˆ†æ {len(selected_symbols)} ä¸ªå“ç§çš„åº“å­˜æ•°æ®..."):
                try:
                    results_df, inventory_trends, data_dict = run_inventory_analysis(
                        selected_symbols, 
                        confidence_level,
                        progress_callback,
                        end_date=end_date,
                        days_back=days_back
                    )
                    
                    if results_df.empty:
                        st.error("æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚")
                        return
                    
                    # ä¿å­˜åˆ°session state
                    st.session_state.inventory_results = (results_df, inventory_trends, data_dict)
                    
                    # æ¸…é™¤è¿›åº¦æ˜¾ç¤º
                    progress_bar.empty()
                    status_text.empty()
                    
                    st.success(f"âœ… æˆåŠŸåˆ†æ {len(results_df)} ä¸ªå“ç§çš„æ•°æ®")
                    
                except Exception as e:
                    progress_bar.empty()
                    status_text.empty()
                    st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                    return
        elif use_existing:
            st.success("âœ… ä½¿ç”¨å·²æœ‰åˆ†ææ•°æ®")
        
        # ä»session stateè·å–æ•°æ®
        if st.session_state.get('inventory_results') is None:
            st.warning("æ²¡æœ‰å¯ç”¨çš„åˆ†æç»“æœï¼Œè¯·é‡æ–°åˆ†æã€‚")
            return
            
        results_df, inventory_trends, data_dict = st.session_state.inventory_results
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        if results_df.empty:
            st.error("åˆ†æç»“æœä¸ºç©ºï¼Œè¯·é‡æ–°åˆ†æã€‚")
            return
        
        # æ˜¾ç¤ºç»“æœ
        st.header("ğŸ“ˆ åº“å­˜åˆ†æç»“æœ")
        
        # æ±‡æ€»ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»å“ç§æ•°", len(results_df))
        with col2:
            st.metric("ç´¯åº“å“ç§", len(inventory_trends['ç´¯åº“å“ç§']), 
                     delta=f"{len(inventory_trends['ç´¯åº“å“ç§'])/len(results_df)*100:.1f}%")
        with col3:
            st.metric("å»åº“å“ç§", len(inventory_trends['å»åº“å“ç§']),
                     delta=f"{len(inventory_trends['å»åº“å“ç§'])/len(results_df)*100:.1f}%")
        with col4:
            st.metric("ç¨³å®šå“ç§", len(inventory_trends['åº“å­˜ç¨³å®šå“ç§']),
                     delta=f"{len(inventory_trends['åº“å­˜ç¨³å®šå“ç§'])/len(results_df)*100:.1f}%")
        
        # æ±‡æ€»å›¾è¡¨
        st.subheader("ğŸ“Š æ±‡æ€»å›¾è¡¨")
        create_summary_charts(results_df, inventory_trends)
        
        # è¯¦ç»†ç»“æœè¡¨æ ¼
        st.subheader("ğŸ“‹ è¯¦ç»†åˆ†æç»“æœ")
        
        # åº“å­˜åˆ†æé€»è¾‘å’ŒåŸç†è¯´æ˜
        with st.expander("ğŸ“– åº“å­˜åˆ†æé€»è¾‘ä¸åŸç†"):
            st.markdown("""
            ### ğŸ” åˆ†æé€»è¾‘è¯´æ˜
            
            #### 1. è¶‹åŠ¿åˆ¤æ–­é€»è¾‘
            **ç´¯åº“/å»åº“åˆ¤æ–­æ ‡å‡†**ï¼š
            - **ä¸»è¦é˜ˆå€¼**ï¼šå˜åŒ–ç‡ > 10% ä¸”å¹³å‡æ—¥å˜åŒ– > 0 â†’ ç´¯åº“
            - **ä¸»è¦é˜ˆå€¼**ï¼šå˜åŒ–ç‡ < -10% ä¸”å¹³å‡æ—¥å˜åŒ– < 0 â†’ å»åº“  
            - **æ¬¡çº§é˜ˆå€¼**ï¼šå˜åŒ–ç‡ > 5% ä¸”è¶‹åŠ¿å¼ºåº¦ > 0.2 â†’ ç´¯åº“
            - **æ¬¡çº§é˜ˆå€¼**ï¼šå˜åŒ–ç‡ < -5% ä¸”è¶‹åŠ¿å¼ºåº¦ > 0.2 â†’ å»åº“
            - **å…¶ä»–æƒ…å†µ**ï¼šåº“å­˜ç¨³å®š
            
            #### 2. å…³é”®æŒ‡æ ‡è®¡ç®—
            **å˜åŒ–ç‡**ï¼š(æœŸæœ«åº“å­˜ - æœŸåˆåº“å­˜) / æœŸåˆåº“å­˜ Ã— 100%
            - åæ˜ åº“å­˜çš„æ€»ä½“å˜åŒ–å¹…åº¦
            - æ­£å€¼è¡¨ç¤ºç´¯åº“ï¼Œè´Ÿå€¼è¡¨ç¤ºå»åº“
            
            **ä¿¡å·å¼ºåº¦**ï¼šabs(å˜åŒ–ç‡) / max(åŠ¨æ€é˜ˆå€¼, å›ºå®šé˜ˆå€¼)
            - ç»¼åˆè€ƒè™‘å˜åŒ–å¹…åº¦å’Œç»Ÿè®¡æ˜¾è‘—æ€§
            - å€¼è¶Šå¤§è¡¨ç¤ºä¿¡å·è¶Šå¯é 
            
            **è¶‹åŠ¿å¼ºåº¦**ï¼š|æ­£å˜åŒ–æ€»å’Œ - è´Ÿå˜åŒ–æ€»å’Œ| / æ€»å˜åŒ–é‡
            - åæ˜ åº“å­˜å˜åŒ–çš„æ–¹å‘ä¸€è‡´æ€§
            - å€¼è¶Šå¤§è¡¨ç¤ºè¶‹åŠ¿è¶Šæ˜ç¡®
            
            **åº“å­˜å‘¨è½¬ç‡**ï¼šåº“å­˜å˜åŒ–æ€»é‡ / å¹³å‡åº“å­˜
            - åæ˜ åº“å­˜çš„æ´»è·ƒç¨‹åº¦
            - å€¼è¶Šå¤§è¡¨ç¤ºåº“å­˜æµåŠ¨æ€§è¶Šå¼º
            
            #### 3. æŠ•èµ„é€»è¾‘
            **ç´¯åº“ä¿¡å·** â†’ **çœ‹ç©ºä¿¡å·**ï¼š
            - åº“å­˜å¢åŠ é€šå¸¸æ„å‘³ç€ä¾›åº”è¿‡å‰©æˆ–éœ€æ±‚ä¸è¶³
            - å¯èƒ½å¯¼è‡´ä»·æ ¼ä¸‹è·Œå‹åŠ›
            - å»ºè®®ï¼šè€ƒè™‘åšç©ºæ“ä½œ
            
            **å»åº“ä¿¡å·** â†’ **çœ‹å¤šä¿¡å·**ï¼š
            - åº“å­˜å‡å°‘é€šå¸¸æ„å‘³ç€éœ€æ±‚æ—ºç››æˆ–ä¾›åº”ç´§å¼ 
            - å¯èƒ½æ¨åŠ¨ä»·æ ¼ä¸Šæ¶¨
            - å»ºè®®ï¼šè€ƒè™‘åšå¤šæ“ä½œ
            
            #### 4. ä¿¡å·å¯é æ€§è¯„ä¼°
            - **ä¿¡å·å¼ºåº¦ > 0.5**ï¼šé«˜å¯é æ€§ä¿¡å·
            - **ä¿¡å·å¼ºåº¦ 0.2-0.5**ï¼šä¸­ç­‰å¯é æ€§ä¿¡å·  
            - **ä¿¡å·å¼ºåº¦ < 0.2**ï¼šå¼±ä¿¡å·ï¼Œéœ€è°¨æ…
            
            ğŸ’¡ **æ³¨æ„**ï¼šåº“å­˜åˆ†æéœ€ç»“åˆä»·æ ¼èµ°åŠ¿ã€åŸºæœ¬é¢ç­‰å› ç´ ç»¼åˆåˆ¤æ–­
            """)
        
        # ç­›é€‰é€‰é¡¹
        col1, col2 = st.columns(2)
        with col1:
            trend_filter = st.selectbox(
                "ç­›é€‰è¶‹åŠ¿ç±»å‹",
                ["å…¨éƒ¨", "ç´¯åº“", "å»åº“", "ç¨³å®š"]
            )
        with col2:
            min_signal_strength = st.slider("æœ€å°ä¿¡å·å¼ºåº¦", 0.0, 1.0, 0.0, 0.1)
        
        # åº”ç”¨ç­›é€‰å’Œæ’åº
        filtered_df = results_df.copy()
        if trend_filter != "å…¨éƒ¨":
            filtered_df = filtered_df[filtered_df['è¶‹åŠ¿'] == trend_filter]
        filtered_df = filtered_df[filtered_df['ä¿¡å·å¼ºåº¦'] >= min_signal_strength]
        
        # æ ¹æ®é€‰æ‹©çš„æ’åºæ–¹å¼æ’åº
        if sort_method == "ä¿¡å·å¼ºåº¦":
            filtered_df = filtered_df.sort_values('ä¿¡å·å¼ºåº¦', ascending=False)
        elif sort_method == "å˜åŒ–ç‡ç»å¯¹å€¼":
            filtered_df = filtered_df.sort_values('å˜åŒ–ç‡', key=abs, ascending=False)
        elif sort_method == "è¶‹åŠ¿å¼ºåº¦":
            filtered_df = filtered_df.sort_values('è¶‹åŠ¿å¼ºåº¦', ascending=False)
        
        # æ£€æŸ¥ç­›é€‰åçš„æ•°æ®
        if filtered_df.empty:
            st.warning("ç­›é€‰æ¡ä»¶è¿‡äºä¸¥æ ¼ï¼Œæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ•°æ®ã€‚è¯·è°ƒæ•´ç­›é€‰æ¡ä»¶ã€‚")
            return
        
        # æ ¼å¼åŒ–æ˜¾ç¤º
        display_df = filtered_df.copy()
        display_df['å˜åŒ–ç‡'] = display_df['å˜åŒ–ç‡'].apply(lambda x: f"{x:.2f}%")
        display_df['ä¿¡å·å¼ºåº¦'] = display_df['ä¿¡å·å¼ºåº¦'].apply(lambda x: f"{x:.3f}")
        display_df['è¶‹åŠ¿å¼ºåº¦'] = display_df['è¶‹åŠ¿å¼ºåº¦'].apply(lambda x: f"{x:.3f}")
        
        st.dataframe(
            display_df,
            use_container_width=True,
            height=400
        )
        
        # å›¾è¡¨å±•ç¤ºé€‰é¡¹
        st.subheader("ğŸ“Š å›¾è¡¨åˆ†æ")
        
        # é€‰æ‹©è¦æŸ¥çœ‹å›¾è¡¨çš„å“ç§
        chart_symbols = st.multiselect(
            "é€‰æ‹©è¦æŸ¥çœ‹å›¾è¡¨çš„å“ç§ï¼ˆæœ€å¤š5ä¸ªï¼‰",
            options=list(data_dict.keys()),
            default=[],
            max_selections=5
        )
        
        if chart_symbols:
            chart_type = st.radio(
                "é€‰æ‹©å›¾è¡¨ç±»å‹",
                ["åº“å­˜èµ°åŠ¿å›¾", "åº“å­˜ä»·æ ¼å¯¹æ¯”å›¾"],
                horizontal=True
            )
            
            # æ˜¾ç¤ºå›¾è¡¨çš„å¼€å…³
            show_charts_key = f"show_inventory_charts_{hash(tuple(chart_symbols))}"
            if show_charts_key not in st.session_state.show_charts:
                st.session_state.show_charts[show_charts_key] = False
            
            col1, col2 = st.columns([1, 4])
            with col1:
                if st.button("ğŸ“ˆ æ˜¾ç¤ºå›¾è¡¨", key=f"show_{show_charts_key}"):
                    st.session_state.show_charts[show_charts_key] = True
            with col2:
                if st.button("ğŸ”„ éšè—å›¾è¡¨", key=f"hide_{show_charts_key}"):
                    st.session_state.show_charts[show_charts_key] = False
            
            # æ˜¾ç¤ºå›¾è¡¨
            if st.session_state.show_charts.get(show_charts_key, False):
                for symbol in chart_symbols:
                    if symbol in data_dict:
                        df = data_dict[symbol]
                        analysis_result = results_df[results_df['å“ç§'] == symbol].iloc[0].to_dict()
                        
                        st.subheader(f"ğŸ“Š {symbol} è¯¦ç»†åˆ†æ")
                        
                        if chart_type == "åº“å­˜èµ°åŠ¿å›¾":
                            # åˆ›å»ºåº“å­˜è¶‹åŠ¿å›¾
                            fig = create_plotly_trend_chart(df, symbol, analysis_result)
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            # åˆ›å»ºåº“å­˜ä»·æ ¼å¯¹æ¯”å›¾
                            with st.spinner(f"æ­£åœ¨è·å–{symbol}çš„ä»·æ ¼æ•°æ®..."):
                                price_df = get_futures_price_data(symbol)
                            
                            if price_df is not None:
                                # æ˜¾ç¤ºåŸå§‹æ•°æ®æ—¶é—´èŒƒå›´
                                inventory_start = df['æ—¥æœŸ'].min().date()
                                inventory_end = df['æ—¥æœŸ'].max().date()
                                price_start = price_df['æ—¥æœŸ'].min().date()
                                price_end = price_df['æ—¥æœŸ'].max().date()
                                
                                st.info(f"ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´ - åº“å­˜: {inventory_start} åˆ° {inventory_end} | ä»·æ ¼: {price_start} åˆ° {price_end}")
                                
                                # å¯¹é½æ•°æ®æ—¶é—´èŒƒå›´
                                aligned_inventory, aligned_price = align_inventory_and_price_data(df, price_df)
                                
                                if len(aligned_inventory) > 0 and len(aligned_price) > 0:
                                    # æ˜¾ç¤ºå¯¹é½åçš„æ—¶é—´èŒƒå›´
                                    aligned_start = max(aligned_inventory['æ—¥æœŸ'].min().date(), aligned_price['æ—¥æœŸ'].min().date())
                                    aligned_end = min(aligned_inventory['æ—¥æœŸ'].max().date(), aligned_price['æ—¥æœŸ'].max().date())
                                    st.success(f"âœ… æ•°æ®å¯¹é½æˆåŠŸ - åˆ†ææ—¶é—´èŒƒå›´: {aligned_start} åˆ° {aligned_end}")
                                    
                                    # åˆ›å»ºåº“å­˜ä»·æ ¼å¯¹æ¯”å›¾
                                    fig = create_plotly_inventory_price_chart(aligned_inventory, aligned_price, symbol, analysis_result)
                                    st.plotly_chart(fig, use_container_width=True)
                                    
                                    # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.metric("åº“å­˜æ•°æ®ç‚¹", len(aligned_inventory))
                                    with col2:
                                        st.metric("ä»·æ ¼æ•°æ®ç‚¹", len(aligned_price))
                                else:
                                    st.warning(f"âš ï¸ {symbol}çš„æ•°æ®å¯¹é½åä¸ºç©ºï¼Œæ˜¾ç¤ºåº“å­˜èµ°åŠ¿å›¾")
                                    fig = create_plotly_trend_chart(df, symbol, analysis_result)
                                    st.plotly_chart(fig, use_container_width=True)
                            else:
                                # æ˜¾ç¤ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                                st.warning(f"âš ï¸ æ— æ³•è·å–{symbol}çš„ä»·æ ¼æ•°æ®")
                                
                                # æœŸè´§åˆçº¦åç§°æ˜ å°„è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼Œç”¨äºæ˜¾ç¤ºå°è¯•çš„åˆçº¦åç§°ï¼‰
                                symbol_mapping = {
                                    'é•': ['NI0', 'é•è¿ç»­', 'NIè¿ç»­'],
                                    'æ²ªé“œ': ['CU0', 'æ²ªé“œè¿ç»­', 'CUè¿ç»­'],
                                    'é”¡': ['SN0', 'é”¡è¿ç»­', 'SNè¿ç»­'],
                                    'æ²ªé“': ['AL0', 'æ²ªé“è¿ç»­', 'ALè¿ç»­'],
                                    'è‹¯ä¹™çƒ¯': ['EB0', 'è‹¯ä¹™çƒ¯è¿ç»­', 'EBè¿ç»­'],
                                    'æ¶²åŒ–çŸ³æ²¹æ°”': ['PG0', 'æ¶²åŒ–çŸ³æ²¹æ°”è¿ç»­', 'PGè¿ç»­'],
                                    'ä½ç¡«ç‡ƒæ–™æ²¹': ['LU0', 'ä½ç¡«ç‡ƒæ–™æ²¹è¿ç»­', 'LUè¿ç»­'],
                                    'å¤šæ™¶ç¡…': ['OQ0', 'å¤šæ™¶ç¡…è¿ç»­', 'OQè¿ç»­'],
                                    'ç¡…é“': ['SF0', 'ç¡…é“è¿ç»­', 'SFè¿ç»­'],
                                    'åŸæœ¨': ['WO0', 'åŸæœ¨è¿ç»­', 'WOè¿ç»­']
                                }
                                
                                tried_names = symbol_mapping.get(symbol, [f"{symbol}0", f"{symbol}è¿ç»­"])
                                st.info(f"ğŸ’¡ å·²å°è¯•çš„åˆçº¦åç§°: {', '.join(tried_names[:3])}...")
                                st.info("ğŸ“ å¯èƒ½çš„åŸå› : 1) è¯¥å“ç§æš‚æ— ä»·æ ¼æ•°æ® 2) åˆçº¦åç§°ä¸åŒ¹é… 3) æ•°æ®æºæš‚æ—¶ä¸å¯ç”¨")
                                
                                # æ˜¾ç¤ºåº“å­˜èµ°åŠ¿å›¾ä½œä¸ºæ›¿ä»£
                                st.info("ğŸ“Š æ˜¾ç¤ºåº“å­˜èµ°åŠ¿å›¾ä½œä¸ºæ›¿ä»£:")
                                fig = create_plotly_trend_chart(df, symbol, analysis_result)
                                st.plotly_chart(fig, use_container_width=True)
                        
                        # å…³é”®æŒ‡æ ‡
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("åº“å­˜å˜åŒ–ç‡", f"{analysis_result['å˜åŒ–ç‡']:.2f}%")
                            st.metric("è¶‹åŠ¿å¼ºåº¦", f"{analysis_result['è¶‹åŠ¿å¼ºåº¦']:.3f}")
                        with col2:
                            st.metric("ä¿¡å·å¼ºåº¦", f"{analysis_result['ä¿¡å·å¼ºåº¦']:.3f}")
                            st.metric("åº“å­˜å‘¨è½¬ç‡", f"{analysis_result['åº“å­˜å‘¨è½¬ç‡']:.3f}")
                        with col3:
                            st.metric("å¹³å‡æ—¥å˜åŒ–", f"{analysis_result['å¹³å‡æ—¥å˜åŒ–']:.2f}")
                            st.metric("åŠ¨æ€é˜ˆå€¼", f"{analysis_result['åŠ¨æ€é˜ˆå€¼']:.2f}")
        
        # é‡ç‚¹å…³æ³¨å“ç§ - æ”¹è¿›æ’åºé€»è¾‘
        if inventory_trends['ç´¯åº“å“ç§'] or inventory_trends['å»åº“å“ç§']:
            st.subheader("âš ï¸ é‡ç‚¹å…³æ³¨å“ç§")
            
            # æ ¹æ®é€‰æ‹©çš„æ’åºæ–¹å¼å¯¹ç´¯åº“å’Œå»åº“å“ç§è¿›è¡Œæ’åº
            def get_sorted_symbols(symbol_list, trend_type):
                """æ ¹æ®æ’åºæ–¹å¼å¯¹å“ç§åˆ—è¡¨è¿›è¡Œæ’åº"""
                if not symbol_list:
                    return pd.DataFrame()
                
                # è·å–è¿™äº›å“ç§çš„æ•°æ®
                trend_df = results_df[results_df['å“ç§'].isin(symbol_list)].copy()
                
                if trend_df.empty:
                    return pd.DataFrame()
                
                # æ ¹æ®æ’åºæ–¹å¼æ’åº
                if sort_method == "ä¿¡å·å¼ºåº¦":
                    trend_df = trend_df.sort_values('ä¿¡å·å¼ºåº¦', ascending=False)
                elif sort_method == "å˜åŒ–ç‡ç»å¯¹å€¼":
                    trend_df = trend_df.sort_values('å˜åŒ–ç‡', key=abs, ascending=False)
                elif sort_method == "è¶‹åŠ¿å¼ºåº¦":
                    trend_df = trend_df.sort_values('è¶‹åŠ¿å¼ºåº¦', ascending=False)
                
                return trend_df
            
            col1, col2 = st.columns(2)
            
            with col1:
                if inventory_trends['ç´¯åº“å“ç§']:
                    st.markdown(f"**ğŸŸ¢ ç´¯åº“å“ç§ (æŒ‰{sort_method}æ’åº)**")
                    sorted_cumulative = get_sorted_symbols(inventory_trends['ç´¯åº“å“ç§'], 'ç´¯åº“')
                    
                    if not sorted_cumulative.empty:
                        for idx, (_, row) in enumerate(sorted_cumulative.head(5).iterrows()):
                            symbol = row['å“ç§']
                            change_rate = row['å˜åŒ–ç‡']
                            signal_strength = row['ä¿¡å·å¼ºåº¦']
                            trend_strength = row['è¶‹åŠ¿å¼ºåº¦']
                            
                            if sort_method == "ä¿¡å·å¼ºåº¦":
                                main_value = f"ä¿¡å·å¼ºåº¦: {signal_strength:.3f}"
                            elif sort_method == "å˜åŒ–ç‡ç»å¯¹å€¼":
                                main_value = f"å˜åŒ–ç‡: {change_rate:.2f}%"
                            else:
                                main_value = f"è¶‹åŠ¿å¼ºåº¦: {trend_strength:.3f}"
                            
                            st.write(f"{idx+1}. **{symbol}**: {main_value}")
                            st.caption(f"   å˜åŒ–ç‡: {change_rate:.2f}% | ä¿¡å·å¼ºåº¦: {signal_strength:.3f}")
                    else:
                        st.info("æš‚æ— ç´¯åº“å“ç§æ•°æ®")
            
            with col2:
                if inventory_trends['å»åº“å“ç§']:
                    st.markdown(f"**ğŸ”´ å»åº“å“ç§ (æŒ‰{sort_method}æ’åº)**")
                    sorted_depletion = get_sorted_symbols(inventory_trends['å»åº“å“ç§'], 'å»åº“')
                    
                    if not sorted_depletion.empty:
                        for idx, (_, row) in enumerate(sorted_depletion.head(5).iterrows()):
                            symbol = row['å“ç§']
                            change_rate = row['å˜åŒ–ç‡']
                            signal_strength = row['ä¿¡å·å¼ºåº¦']
                            trend_strength = row['è¶‹åŠ¿å¼ºåº¦']
                            
                            if sort_method == "ä¿¡å·å¼ºåº¦":
                                main_value = f"ä¿¡å·å¼ºåº¦: {signal_strength:.3f}"
                            elif sort_method == "å˜åŒ–ç‡ç»å¯¹å€¼":
                                main_value = f"å˜åŒ–ç‡: {change_rate:.2f}%"
                            else:
                                main_value = f"è¶‹åŠ¿å¼ºåº¦: {trend_strength:.3f}"
                            
                            st.write(f"{idx+1}. **{symbol}**: {main_value}")
                            st.caption(f"   å˜åŒ–ç‡: {change_rate:.2f}% | ä¿¡å·å¼ºåº¦: {signal_strength:.3f}")
                    else:
                        st.info("æš‚æ— å»åº“å“ç§æ•°æ®")
        
        # å¯¼å‡ºåŠŸèƒ½
        st.subheader("ğŸ“¥ å¯¼å‡ºåˆ†æç»“æœ")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ“Š å¯¼å‡ºExcelæŠ¥å‘Š"):
                try:
                    exporter = get_report_exporter()
                    filepath = exporter.export_inventory_excel(results_df, inventory_trends, data_dict)
                    
                    with open(filepath, 'rb') as f:
                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½ExcelæŠ¥å‘Š",
                            data=f.read(),
                            file_name=filepath.name,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    st.success("ExcelæŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                except Exception as e:
                    st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
        
        with col2:
            if st.button("ğŸ“ˆ å¯¼å‡ºCSVæ•°æ®"):
                csv = results_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½CSVæ•°æ®",
                    data=csv,
                    file_name=f"åº“å­˜åˆ†æç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
        
        with col3:
            if st.button("ğŸ“‹ å¤åˆ¶åˆ†ææ‘˜è¦"):
                # å®‰å…¨åœ°è·å–æ’åºåçš„å“ç§åˆ—è¡¨
                def safe_get_sorted_symbols(symbol_list):
                    if not symbol_list:
                        return []
                    trend_df = results_df[results_df['å“ç§'].isin(symbol_list)].copy()
                    if trend_df.empty:
                        return []
                    
                    if sort_method == "ä¿¡å·å¼ºåº¦":
                        trend_df = trend_df.sort_values('ä¿¡å·å¼ºåº¦', ascending=False)
                    elif sort_method == "å˜åŒ–ç‡ç»å¯¹å€¼":
                        trend_df = trend_df.sort_values('å˜åŒ–ç‡', key=abs, ascending=False)
                    elif sort_method == "è¶‹åŠ¿å¼ºåº¦":
                        trend_df = trend_df.sort_values('è¶‹åŠ¿å¼ºåº¦', ascending=False)
                    
                    return trend_df['å“ç§'].head(5).tolist()
                
                cumulative_symbols = safe_get_sorted_symbols(inventory_trends['ç´¯åº“å“ç§'])
                depletion_symbols = safe_get_sorted_symbols(inventory_trends['å»åº“å“ç§'])
                
                summary_text = f"""
åº“å­˜åˆ†ææ‘˜è¦ ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})
=====================================
åˆ†æå‚æ•°: æˆªæ­¢æ—¥æœŸ{end_date}, åˆ†æ{days_back}å¤©æ•°æ®
æ’åºæ–¹å¼: {sort_method}
æ€»å“ç§æ•°: {len(results_df)}
ç´¯åº“å“ç§: {len(inventory_trends['ç´¯åº“å“ç§'])} ä¸ª
å»åº“å“ç§: {len(inventory_trends['å»åº“å“ç§'])} ä¸ª
ç¨³å®šå“ç§: {len(inventory_trends['åº“å­˜ç¨³å®šå“ç§'])} ä¸ª

é‡ç‚¹ç´¯åº“å“ç§: {', '.join(cumulative_symbols)}
é‡ç‚¹å»åº“å“ç§: {', '.join(depletion_symbols)}
"""
                st.code(summary_text)
                st.info("æ‘˜è¦å·²æ˜¾ç¤ºï¼Œå¯æ‰‹åŠ¨å¤åˆ¶")

def basis_analysis_page():
    """åŸºå·®åˆ†æé¡µé¢"""
    st.header("ğŸ’° æœŸè´§åŸºå·®åˆ†æ")
    
    # å‚æ•°è®¾ç½®
    st.subheader("ğŸ”§ åˆ†æå‚æ•°è®¾ç½®")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        end_date = st.date_input("ç»“æŸæ—¥æœŸ", value=datetime.now().date())
        end_day = end_date.strftime("%Y%m%d")
    
    with col2:
        days_back = st.slider("åˆ†æå¤©æ•°", min_value=15, max_value=90, value=30)
    
    with col3:
        min_confidence = st.slider("æœ€ä½ç½®ä¿¡åº¦(%)", min_value=20, max_value=80, value=50)
    
    with col4:
        st.write("ç¼“å­˜çŠ¶æ€")
        cache_info = f"å†…å­˜ç¼“å­˜: {len(cache_manager.memory_cache)} é¡¹"
        st.info(cache_info)
    
    # ç½®ä¿¡åº¦è¯´æ˜
    with st.expander("ğŸ“– ç½®ä¿¡åº¦è¯´æ˜"):
        st.markdown("""
        **ç½®ä¿¡åº¦æ˜¯ä»€ä¹ˆï¼Ÿ**
        - ç½®ä¿¡åº¦è¡¨ç¤ºåŸºå·®æŠ•èµ„æœºä¼šæˆåŠŸçš„é¢„æœŸæ¦‚ç‡
        - å®ƒæ˜¯åŸºäºå¤šä¸ªæŠ€æœ¯æŒ‡æ ‡ç»¼åˆè®¡ç®—å¾—å‡ºçš„è¯„åˆ†ï¼ˆ0-100%ï¼‰
        
        **ç½®ä¿¡åº¦è®¡ç®—å› å­ï¼š**
        - **Z-Scoreæƒé‡æœ€é«˜**ï¼šåŸºå·®åç¦»å†å²å‡å€¼çš„æ ‡å‡†åŒ–ç¨‹åº¦
        - **è¶‹åŠ¿åè½¬ä¿¡å·**ï¼šåŸºå·®è¶‹åŠ¿æ˜¯å¦å‡ºç°åè½¬è¿¹è±¡
        - **RSIæŒ‡æ ‡**ï¼šåŸºå·®æ˜¯å¦å¤„äºè¶…ä¹°/è¶…å–çŠ¶æ€
        - **å¸ƒæ—å¸¦ä½ç½®**ï¼šåŸºå·®åœ¨å¸ƒæ—å¸¦ä¸­çš„ç›¸å¯¹ä½ç½®
        - **æ³¢åŠ¨ç‡è°ƒæ•´**ï¼šæ ¹æ®å“ç§æ³¢åŠ¨ç‡ç‰¹å¾è¿›è¡Œè°ƒæ•´
        
        **ä¸ºä»€ä¹ˆæŒ‰ç½®ä¿¡åº¦æ’åºï¼Ÿ**
        - ç½®ä¿¡åº¦é«˜çš„æœºä¼šï¼ŒåŸºå·®å›å½’çš„æ¦‚ç‡æ›´å¤§
        - ç»¼åˆè€ƒè™‘äº†å¤šä¸ªç»´åº¦ï¼Œæ¯”å•ä¸€æŒ‡æ ‡æ›´å¯é 
        - æœ‰åŠ©äºæŠ•èµ„è€…ä¼˜å…ˆå…³æ³¨æœ€æœ‰æŠŠæ¡çš„æœºä¼š
        
        **ç½®ä¿¡åº¦é˜ˆå€¼å»ºè®®ï¼š**
        - **ä¿å®ˆå‹**ï¼š60-70%ä»¥ä¸Šï¼ˆæœºä¼šè¾ƒå°‘ä½†è´¨é‡é«˜ï¼‰
        - **å¹³è¡¡å‹**ï¼š40-50%ä»¥ä¸Šï¼ˆæœºä¼šä¸è´¨é‡å¹³è¡¡ï¼‰
        - **æ¿€è¿›å‹**ï¼š30-40%ä»¥ä¸Šï¼ˆæœºä¼šè¾ƒå¤šä½†éœ€è°¨æ…ï¼‰
        """)
    
    # åˆ†ææŒ‰é’®
    col1, col2, col3 = st.columns([1, 1, 3])
    with col1:
        start_analysis = st.button("ğŸš€ å¼€å§‹åŸºå·®åˆ†æ", type="primary")
    with col2:
        if st.button("ğŸ”„ é‡æ–°åˆ†æ"):
            if 'basis_results' in st.session_state:
                del st.session_state.basis_results
            cache_manager.clear_expired()
            st.rerun()
    with col3:
        if st.button("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰ç¼“å­˜"):
            cache_manager.clear_expired()
            st.session_state.clear()
            st.success("ç¼“å­˜å·²æ¸…é™¤")
            st.rerun()
    
    # æ‰§è¡Œåˆ†æ
    if start_analysis or st.session_state.get('basis_results') is not None:
        
        # å¦‚æœæ˜¯æ–°çš„åˆ†æè¯·æ±‚ï¼Œæ‰§è¡Œåˆ†æ
        if start_analysis:
            strategy = FuturesBasisStrategy()
            
            # åˆ›å»ºè¿›åº¦æ˜¾ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            def progress_callback(current, total, message):
                progress_bar.progress(current / total)
                status_text.text(f"{message} [{current}/{total}]")
            
            with st.spinner("æ­£åœ¨åˆ†æåŸºå·®æ•°æ®..."):
                try:
                    opportunities = strategy.run_analysis_streamlit(
                        end_day=end_day,
                        days_back=days_back,
                        min_confidence=min_confidence,
                        progress_callback=progress_callback
                    )
                    
                    # ä¿å­˜åˆ°session state
                    st.session_state.basis_results = (opportunities, strategy)
                    
                    # æ¸…é™¤è¿›åº¦æ˜¾ç¤º
                    progress_bar.empty()
                    status_text.empty()
                    
                    if opportunities:
                        st.success(f"ğŸ¯ å‘ç° {len(opportunities)} ä¸ªæŠ•èµ„æœºä¼šï¼")
                    else:
                        st.warning("æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„æŠ•èµ„æœºä¼š")
                        
                except Exception as e:
                    progress_bar.empty()
                    status_text.empty()
                    st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                    return
        
        # ä»session stateè·å–æ•°æ®
        if st.session_state.get('basis_results') is None:
            st.warning("æ²¡æœ‰å¯ç”¨çš„åˆ†æç»“æœï¼Œè¯·é‡æ–°åˆ†æã€‚")
            return
            
        opportunities, strategy = st.session_state.basis_results
        
        # æ˜¾ç¤ºç»“æœ
        if opportunities:
            st.header("ğŸ’° åŸºå·®åˆ†æç»“æœ")
            
            # åŸºå·®åˆ†æé€»è¾‘å’ŒåŸç†è¯´æ˜
            with st.expander("ğŸ“– åŸºå·®åˆ†æé€»è¾‘ä¸åŸç†"):
                st.markdown("""
                ### ğŸ” åŸºå·®åˆ†ææ ¸å¿ƒåŸç†
                
                #### 1. åŸºå·®å®šä¹‰ä¸è®¡ç®—
                **åŸºå·® = ç°è´§ä»·æ ¼ - æœŸè´§ä»·æ ¼**
                - æ­£åŸºå·®ï¼šç°è´§ä»·æ ¼ > æœŸè´§ä»·æ ¼ï¼ˆç°è´§å‡æ°´ï¼‰
                - è´ŸåŸºå·®ï¼šç°è´§ä»·æ ¼ < æœŸè´§ä»·æ ¼ï¼ˆæœŸè´§å‡æ°´ï¼‰
                - åŸºå·®ä¼šå›´ç»•å†å²å‡å€¼æ³¢åŠ¨ï¼Œå­˜åœ¨å›å½’ç‰¹æ€§
                
                #### 2. æŠ•èµ„æœºä¼šè¯†åˆ«é€»è¾‘
                
                **Z-Scoreæ ‡å‡†åŒ–**ï¼š
                ```
                Z-Score = (å½“å‰åŸºå·® - å†å²å‡å€¼) / å†å²æ ‡å‡†å·®
                ```
                
                **æœºä¼šç±»å‹åˆ¤æ–­**ï¼š
                - **Z-Score < -1.5** â†’ **ä¹°åŸºå·®æœºä¼š**ï¼ˆæœŸè´§è¢«é«˜ä¼°ï¼‰
                - **Z-Score > 1.5** â†’ **å–åŸºå·®æœºä¼š**ï¼ˆç°è´§è¢«é«˜ä¼°ï¼‰
                - **-1.5 â‰¤ Z-Score â‰¤ 1.5** â†’ æ ¹æ®å¼ºåº¦åˆ¤æ–­å¼±æœºä¼š
                
                #### 3. ç½®ä¿¡åº¦è®¡ç®—ä½“ç³»
                
                **åŸºç¡€è¯„åˆ†**ï¼š
                - æç«¯æœºä¼šï¼ˆ|Z-Score| > 1.5ï¼‰ï¼šåŸºç¡€åˆ† = min(|Z-Score| Ã— 30, 85)
                - ä¸­ç­‰æœºä¼šï¼ˆ|Z-Score| > 1.0ï¼‰ï¼šåŸºç¡€åˆ† = min(|Z-Score| Ã— 25, 70)
                - å¼±æœºä¼šï¼ˆ|Z-Score| > 0.8ï¼‰ï¼šåŸºç¡€åˆ† = min(|Z-Score| Ã— 20, 50)
                
                **æŠ€æœ¯æŒ‡æ ‡è°ƒæ•´**ï¼š
                - **è¶‹åŠ¿åè½¬ä¿¡å·**ï¼šÂ±8åˆ†è°ƒæ•´
                - **RSIè¶…ä¹°è¶…å–**ï¼šÂ±4åˆ†è°ƒæ•´ï¼ˆRSI<35æˆ–RSI>65ï¼‰
                - **å¸ƒæ—å¸¦ä½ç½®**ï¼šÂ±4åˆ†è°ƒæ•´ï¼ˆä½ç½®<25%æˆ–>75%ï¼‰
                - **æ³¢åŠ¨ç‡è°ƒæ•´**ï¼šé«˜æ³¢åŠ¨ç‡Ã—0.85ï¼Œä½æ³¢åŠ¨ç‡Ã—1.05
                
                #### 4. æŠ•èµ„æ“ä½œç­–ç•¥
                
                **ä¹°åŸºå·®æ“ä½œ**ï¼ˆåšç©ºæœŸè´§ä¿¡å·ï¼‰ï¼š
                - **æ“ä½œ**ï¼šä¹°å…¥ç°è´§ + å–å‡ºæœŸè´§
                - **é€»è¾‘**ï¼šæœŸè´§ä»·æ ¼ç›¸å¯¹ç°è´§è¢«é«˜ä¼°ï¼Œç­‰å¾…åŸºå·®å›å½’
                - **ç›ˆåˆ©æ–¹å¼**ï¼šæœŸè´§ä»·æ ¼ä¸‹è·Œæˆ–ç°è´§ä»·æ ¼ä¸Šæ¶¨
                
                **å–åŸºå·®æ“ä½œ**ï¼ˆåšå¤šæœŸè´§ä¿¡å·ï¼‰ï¼š
                - **æ“ä½œ**ï¼šå–å‡ºç°è´§ + ä¹°å…¥æœŸè´§  
                - **é€»è¾‘**ï¼šç°è´§ä»·æ ¼ç›¸å¯¹æœŸè´§è¢«é«˜ä¼°ï¼Œç­‰å¾…åŸºå·®å›å½’
                - **ç›ˆåˆ©æ–¹å¼**ï¼šæœŸè´§ä»·æ ¼ä¸Šæ¶¨æˆ–ç°è´§ä»·æ ¼ä¸‹è·Œ
                
                #### 5. é£é™©è¯„ä¼°ä½“ç³»
                
                **é£é™©ç­‰çº§åˆ¤æ–­**ï¼š
                - **æ³¢åŠ¨ç‡é£é™©**ï¼šé«˜æ³¢åŠ¨ç‡å¢åŠ é£é™©åˆ†æ•°
                - **æç«¯ç¨‹åº¦é£é™©**ï¼š|Z-Score|è¿‡å¤§å¢åŠ é£é™©
                - **æ•°æ®è´¨é‡é£é™©**ï¼šæ•°æ®ä¸è¶³å¢åŠ é£é™©
                - **è¶‹åŠ¿ä¸€è‡´æ€§**ï¼šç°è´§æœŸè´§è¶‹åŠ¿èƒŒç¦»å¢åŠ é£é™©
                
                **é£é™©åˆ†çº§**ï¼š
                - **ä½é£é™©**ï¼šé£é™©åˆ†æ•° < 3ï¼Œé€‚åˆç¨³å¥æŠ•èµ„è€…
                - **ä¸­é£é™©**ï¼šé£é™©åˆ†æ•° 3-4ï¼Œéœ€è¦ä¸€å®šé£é™©æ‰¿å—èƒ½åŠ›
                - **é«˜é£é™©**ï¼šé£é™©åˆ†æ•° â‰¥ 5ï¼Œä»…é€‚åˆæ¿€è¿›æŠ•èµ„è€…
                
                #### 6. æŠ•èµ„å†³ç­–å»ºè®®
                
                **æœºä¼šé€‰æ‹©ä¼˜å…ˆçº§**ï¼š
                1. **ç½®ä¿¡åº¦ > 70%** + **ä½é£é™©** â†’ ä¼˜å…ˆè€ƒè™‘
                2. **ç½®ä¿¡åº¦ 60-70%** + **ä¸­é£é™©** â†’ è°¨æ…è€ƒè™‘
                3. **ç½®ä¿¡åº¦ < 60%** æˆ– **é«˜é£é™©** â†’ è§‚æœ›æˆ–å°ä»“ä½è¯•æ¢
                
                **æŒä»“æœŸå»ºè®®**ï¼š
                - åŸºäºZ-Scoreç»å¯¹å€¼è®¡ç®—ï¼š|Z-Score|è¶Šå¤§ï¼Œå»ºè®®æŒä»“æœŸè¶ŠçŸ­
                - ä¸€èˆ¬å»ºè®®10-30å¤©ï¼Œç­‰å¾…åŸºå·®å›å½’
                
                ğŸ’¡ **æ ¸å¿ƒç†å¿µ**ï¼šåŸºå·®äº¤æ˜“æœ¬è´¨æ˜¯ç»Ÿè®¡å¥—åˆ©ï¼Œåˆ©ç”¨ä»·æ ¼å…³ç³»çš„å¼‚å¸¸è¿›è¡ŒæŠ•èµ„
                """)
            
            # æ’åºè¯´æ˜
            st.info("""
            ğŸ“Š **ç»“æœæ’åºè¯´æ˜**ï¼š
            - ç»“æœæŒ‰**ç½®ä¿¡åº¦ä»é«˜åˆ°ä½**æ’åº
            - ç½®ä¿¡åº¦è¶Šé«˜ï¼Œè¡¨ç¤ºåŸºå·®å›å½’çš„å¯èƒ½æ€§è¶Šå¤§
            - å»ºè®®ä¼˜å…ˆå…³æ³¨ç½®ä¿¡åº¦è¾ƒé«˜çš„æŠ•èµ„æœºä¼š
            """)
            
            # åˆ›å»ºç»“æœè¡¨æ ¼
            results_data = []
            for opp in opportunities:
                signal_strength = "ğŸ”´æç«¯" if abs(opp.z_score) > 2.0 else "ğŸŸ¡ä¸­ç­‰" if abs(opp.z_score) > 1.5 else "ğŸŸ¢å¼±"
                results_data.append({
                    "å“ç§": opp.name,
                    "ä»£ç ": opp.variety,
                    "ä¿¡å·å¼ºåº¦": signal_strength,
                    "æœºä¼šç±»å‹": opp.opportunity_type,
                    "ç½®ä¿¡åº¦(%)": f"{opp.confidence:.1f}%",
                    "é¢„æœŸæ”¶ç›Š(%)": f"{opp.expected_return:.1f}%",
                    "é£é™©ç­‰çº§": opp.risk_level,
                    "å»ºè®®æŒä»“(å¤©)": opp.holding_period,
                    "Z-Score": f"{opp.z_score:.2f}",
                    "å½“å‰åŸºå·®": f"{opp.current_basis:.2f}"
                })
            
            results_df = pd.DataFrame(results_data)
            
            # ç­›é€‰é€‰é¡¹
            st.subheader("ğŸ” ç­›é€‰é€‰é¡¹")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                opportunity_filter = st.selectbox(
                    "æœºä¼šç±»å‹ç­›é€‰",
                    ["å…¨éƒ¨", "ä¹°åŸºå·®æœºä¼š", "å–åŸºå·®æœºä¼š", "å¼±ä¹°åŸºå·®æœºä¼š", "å¼±å–åŸºå·®æœºä¼š"]
                )
            
            with col2:
                risk_filter = st.selectbox(
                    "é£é™©ç­‰çº§ç­›é€‰",
                    ["å…¨éƒ¨", "ä½é£é™©", "ä¸­é£é™©", "é«˜é£é™©"]
                )
            
            with col3:
                min_confidence_display = st.slider("æ˜¾ç¤ºç½®ä¿¡åº¦é˜ˆå€¼(%)", 0, 95, min_confidence)
            
            # åº”ç”¨ç­›é€‰
            filtered_opportunities = opportunities.copy()
            if opportunity_filter != "å…¨éƒ¨":
                filtered_opportunities = [opp for opp in filtered_opportunities if opp.opportunity_type == opportunity_filter]
            if risk_filter != "å…¨éƒ¨":
                filtered_opportunities = [opp for opp in filtered_opportunities if opp.risk_level == risk_filter]
            filtered_opportunities = [opp for opp in filtered_opportunities if opp.confidence >= min_confidence_display]
            
            # æ›´æ–°æ˜¾ç¤ºè¡¨æ ¼
            if filtered_opportunities:
                filtered_results_data = []
                for opp in filtered_opportunities:
                    signal_strength = "ğŸ”´æç«¯" if abs(opp.z_score) > 2.0 else "ğŸŸ¡ä¸­ç­‰" if abs(opp.z_score) > 1.5 else "ğŸŸ¢å¼±"
                    filtered_results_data.append({
                        "å“ç§": opp.name,
                        "ä»£ç ": opp.variety,
                        "ä¿¡å·å¼ºåº¦": signal_strength,
                        "æœºä¼šç±»å‹": opp.opportunity_type,
                        "ç½®ä¿¡åº¦(%)": f"{opp.confidence:.1f}%",
                        "é¢„æœŸæ”¶ç›Š(%)": f"{opp.expected_return:.1f}%",
                        "é£é™©ç­‰çº§": opp.risk_level,
                        "å»ºè®®æŒä»“(å¤©)": opp.holding_period,
                        "Z-Score": f"{opp.z_score:.2f}",
                        "å½“å‰åŸºå·®": f"{opp.current_basis:.2f}"
                    })
                
                filtered_results_df = pd.DataFrame(filtered_results_data)
                st.dataframe(filtered_results_df, use_container_width=True)
            else:
                st.warning("æ²¡æœ‰ç¬¦åˆç­›é€‰æ¡ä»¶çš„æŠ•èµ„æœºä¼š")
            
            # ç»Ÿè®¡æ‘˜è¦
            st.subheader("ğŸ“Š åˆ†ææ‘˜è¦")
            col1, col2, col3, col4 = st.columns(4)
            
            buy_basis_count = len([o for o in opportunities if 'ä¹°åŸºå·®' in o.opportunity_type])
            sell_basis_count = len([o for o in opportunities if 'å–åŸºå·®' in o.opportunity_type])
            avg_confidence = np.mean([o.confidence for o in opportunities])
            avg_return = np.mean([o.expected_return for o in opportunities])
            
            with col1:
                st.metric("æ€»æœºä¼šæ•°", len(opportunities))
            with col2:
                st.metric("ä¹°åŸºå·®æœºä¼š", buy_basis_count)
            with col3:
                st.metric("å–åŸºå·®æœºä¼š", sell_basis_count)
            with col4:
                st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.1f}%")
            
            # é£é™©åˆ†å¸ƒ
            risk_dist = {}
            for opp in opportunities:
                risk_dist[opp.risk_level] = risk_dist.get(opp.risk_level, 0) + 1
            
            st.subheader("âš ï¸ é£é™©åˆ†å¸ƒ")
            risk_cols = st.columns(3)
            with risk_cols[0]:
                st.metric("ä½é£é™©", risk_dist.get("ä½é£é™©", 0))
            with risk_cols[1]:
                st.metric("ä¸­é£é™©", risk_dist.get("ä¸­é£é™©", 0))
            with risk_cols[2]:
                st.metric("é«˜é£é™©", risk_dist.get("é«˜é£é™©", 0))
            
            # è¯¦ç»†å›¾è¡¨åˆ†æ
            st.subheader("ğŸ“Š è¯¦ç»†å›¾è¡¨åˆ†æ")
            
            # é€‰æ‹©è¦æŸ¥çœ‹å›¾è¡¨çš„å“ç§
            available_varieties = [opp.variety for opp in opportunities if opp.variety in strategy.analysis_results]
            chart_varieties = st.multiselect(
                "é€‰æ‹©è¦æŸ¥çœ‹è¯¦ç»†åˆ†æçš„å“ç§ï¼ˆæœ€å¤š3ä¸ªï¼‰",
                options=available_varieties,
                default=[],
                max_selections=3,
                format_func=lambda x: next(opp.name for opp in opportunities if opp.variety == x)
            )
            
            if chart_varieties:
                # æ˜¾ç¤ºå›¾è¡¨çš„å¼€å…³
                show_charts_key = f"show_basis_charts_{hash(tuple(chart_varieties))}"
                if show_charts_key not in st.session_state.show_charts:
                    st.session_state.show_charts[show_charts_key] = False
                
                col1, col2 = st.columns([1, 4])
                with col1:
                    if st.button("ğŸ“ˆ æ˜¾ç¤ºè¯¦ç»†å›¾è¡¨", key=f"show_{show_charts_key}"):
                        st.session_state.show_charts[show_charts_key] = True
                with col2:
                    if st.button("ğŸ”„ éšè—å›¾è¡¨", key=f"hide_{show_charts_key}"):
                        st.session_state.show_charts[show_charts_key] = False
                
                # æ˜¾ç¤ºå›¾è¡¨
                if st.session_state.show_charts.get(show_charts_key, False):
                    for variety in chart_varieties:
                        if variety in strategy.analysis_results:
                            opportunity = next(opp for opp in opportunities if opp.variety == variety)
                            show_basis_detailed_chart(strategy.analysis_results[variety], opportunity)
            
            # æŠ•èµ„å»ºè®®æ±‡æ€»
            st.subheader("ğŸ’¡ æŠ•èµ„å»ºè®®æ±‡æ€»")
            
            # æŒ‰æœºä¼šç±»å‹åˆ†ç»„
            buy_basis_opps = [opp for opp in opportunities if 'ä¹°åŸºå·®' in opp.opportunity_type]
            sell_basis_opps = [opp for opp in opportunities if 'å–åŸºå·®' in opp.opportunity_type]
            
            col1, col2 = st.columns(2)
            
            with col1:
                if buy_basis_opps:
                    st.markdown("**ğŸŸ¢ ä¹°åŸºå·®æœºä¼šï¼ˆåšç©ºä¿¡å·ï¼‰**")
                    for opp in buy_basis_opps[:5]:
                        st.write(f"â€¢ {opp.name}: ç½®ä¿¡åº¦ {opp.confidence:.1f}%, é¢„æœŸæ”¶ç›Š {opp.expected_return:.1f}%")
                    
                    st.info("ğŸ’¡ ä¹°åŸºå·®æ“ä½œï¼šä¹°å…¥ç°è´§ + å–å‡ºæœŸè´§ï¼ˆç±»ä¼¼åšç©ºæœŸè´§ï¼‰")
            
            with col2:
                if sell_basis_opps:
                    st.markdown("**ğŸ”´ å–åŸºå·®æœºä¼šï¼ˆåšå¤šä¿¡å·ï¼‰**")
                    for opp in sell_basis_opps[:5]:
                        st.write(f"â€¢ {opp.name}: ç½®ä¿¡åº¦ {opp.confidence:.1f}%, é¢„æœŸæ”¶ç›Š {opp.expected_return:.1f}%")
                    
                    st.info("ğŸ’¡ å–åŸºå·®æ“ä½œï¼šå–å‡ºç°è´§ + ä¹°å…¥æœŸè´§ï¼ˆç±»ä¼¼åšå¤šæœŸè´§ï¼‰")
            
            # å¯¼å‡ºåŠŸèƒ½
            st.subheader("ğŸ“¥ å¯¼å‡ºåˆ†æç»“æœ")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("ğŸ“Š å¯¼å‡ºExcelæŠ¥å‘Š"):
                    try:
                        exporter = get_report_exporter()
                        filepath = exporter.export_basis_excel(opportunities, strategy.analysis_stats)
                        
                        with open(filepath, 'rb') as f:
                            st.download_button(
                                label="â¬‡ï¸ ä¸‹è½½ExcelæŠ¥å‘Š",
                                data=f.read(),
                                file_name=filepath.name,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                        st.success("ExcelæŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
            
            with col2:
                if st.button("ğŸ“ˆ å¯¼å‡ºCSVæ•°æ®"):
                    csv = results_df.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½CSVæ•°æ®",
                        data=csv,
                        file_name=f"åŸºå·®åˆ†æç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
            
            with col3:
                if st.button("ğŸ“‹ å¤åˆ¶åˆ†ææ‘˜è¦"):
                    summary_text = f"""
åŸºå·®åˆ†ææ‘˜è¦ ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})
=====================================
åˆ†æå‚æ•°: {days_back}å¤©æ•°æ®, æœ€ä½ç½®ä¿¡åº¦{min_confidence}%
æ’åºæ–¹å¼: æŒ‰ç½®ä¿¡åº¦ä»é«˜åˆ°ä½
æ€»æœºä¼šæ•°: {len(opportunities)}
ä¹°åŸºå·®æœºä¼š: {buy_basis_count} ä¸ª
å–åŸºå·®æœºä¼š: {sell_basis_count} ä¸ª
å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.1f}%
å¹³å‡é¢„æœŸæ”¶ç›Š: {avg_return:.1f}%

é‡ç‚¹ä¹°åŸºå·®å“ç§: {', '.join([opp.name for opp in buy_basis_opps[:3]])}
é‡ç‚¹å–åŸºå·®å“ç§: {', '.join([opp.name for opp in sell_basis_opps[:3]])}
"""
                    st.code(summary_text)
                    st.info("æ‘˜è¦å·²æ˜¾ç¤ºï¼Œå¯æ‰‹åŠ¨å¤åˆ¶")
        
        else:
            st.warning("æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„æŠ•èµ„æœºä¼š")
            st.info("ğŸ’¡ å»ºè®®å°è¯•é™ä½ç½®ä¿¡åº¦é˜ˆå€¼æˆ–å¢åŠ åˆ†æå¤©æ•°")
            
            # æ˜¾ç¤ºåˆ†æç»Ÿè®¡ä¿¡æ¯
            if hasattr(strategy, 'analysis_stats'):
                st.subheader("ğŸ“Š åˆ†æç»Ÿè®¡")
                stats = strategy.analysis_stats
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æˆåŠŸè·å–æ•°æ®", len(stats['successful_varieties']))
                with col2:
                    st.metric("è·å–å¤±è´¥", len(stats['failed_varieties']))
                with col3:
                    st.metric("æ£€æµ‹åˆ°ä¿¡å·", len(stats['analyzed_varieties']))
                
                # æ˜¾ç¤ºæ¥è¿‘é˜ˆå€¼çš„æœºä¼š
                near_threshold = [v for v in stats['analyzed_varieties'] if v['confidence'] >= min_confidence * 0.8]
                if near_threshold:
                    st.subheader("ğŸ’¡ æ¥è¿‘é˜ˆå€¼çš„æœºä¼š")
                    for variety in sorted(near_threshold, key=lambda x: x['confidence'], reverse=True)[:5]:
                        st.write(f"â€¢ {variety['name']}: {variety['opportunity_type']} | ç½®ä¿¡åº¦: {variety['confidence']:.1f}%")
                    st.info(f"å»ºè®®: å¯è€ƒè™‘é™ä½ç½®ä¿¡åº¦é˜ˆå€¼è‡³ {min_confidence*0.8:.0f}% æˆ–æ›´ä½")

def comprehensive_analysis_page():
    """ç»¼åˆåˆ†æé¡µé¢"""
    st.header("ğŸ” ç»¼åˆåŸºæœ¬é¢åˆ†æ")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†æç»“æœ
    has_inventory = st.session_state.get('inventory_results') is not None
    has_basis = st.session_state.get('basis_results') is not None
    
    if not has_inventory and not has_basis:
        st.warning("è¯·å…ˆè¿›è¡Œåº“å­˜åˆ†ææˆ–åŸºå·®åˆ†æï¼Œç„¶åå†æŸ¥çœ‹ç»¼åˆåˆ†æç»“æœã€‚")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”— å‰å¾€åº“å­˜åˆ†æ"):
                st.session_state.page = "åº“å­˜åˆ†æ"
                st.rerun()
        with col2:
            if st.button("ğŸ”— å‰å¾€åŸºå·®åˆ†æ"):
                st.session_state.page = "åŸºå·®åˆ†æ"
                st.rerun()
        return
    
    # è·å–åˆ†æç»“æœ
    inventory_results = st.session_state.get('inventory_results')
    basis_results = st.session_state.get('basis_results')
    
    st.subheader("ğŸ“Š åˆ†æç»“æœæ¦‚è§ˆ")
    
    # æ˜¾ç¤ºå„æ¨¡å—çš„åˆ†æç»“æœ
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“ˆ åº“å­˜åˆ†æç»“æœ")
        if has_inventory:
            results_df, inventory_trends, data_dict = inventory_results
            
            # åº“å­˜åˆ†ææ‘˜è¦
            st.metric("åˆ†æå“ç§æ•°", len(results_df))
            
            col1_1, col1_2, col1_3 = st.columns(3)
            with col1_1:
                st.metric("ç´¯åº“å“ç§", len(inventory_trends['ç´¯åº“å“ç§']))
            with col1_2:
                st.metric("å»åº“å“ç§", len(inventory_trends['å»åº“å“ç§']))
            with col1_3:
                st.metric("ç¨³å®šå“ç§", len(inventory_trends['åº“å­˜ç¨³å®šå“ç§']))
            
            # æ˜¾ç¤ºæ‰€æœ‰ç´¯åº“å“ç§
            if inventory_trends['ç´¯åº“å“ç§']:
                st.markdown("**ğŸŸ¢ æ‰€æœ‰ç´¯åº“å“ç§ï¼ˆåšç©ºä¿¡å·ï¼‰:**")
                # æŒ‰ä¿¡å·å¼ºåº¦æ’åºç´¯åº“å“ç§
                cumulative_symbols = []
                for symbol in inventory_trends['ç´¯åº“å“ç§']:
                    change_rate = results_df[results_df['å“ç§'] == symbol]['å˜åŒ–ç‡'].iloc[0]
                    signal_strength = results_df[results_df['å“ç§'] == symbol]['ä¿¡å·å¼ºåº¦'].iloc[0]
                    cumulative_symbols.append((symbol, change_rate, signal_strength))
                
                # æŒ‰ä¿¡å·å¼ºåº¦é™åºæ’åº
                cumulative_symbols.sort(key=lambda x: x[2], reverse=True)
                
                # æ˜¾ç¤ºæ‰€æœ‰ç´¯åº“å“ç§
                for symbol, change_rate, signal_strength in cumulative_symbols:
                    st.write(f"â€¢ {symbol}: {change_rate:.2f}% (ä¿¡å·å¼ºåº¦: {signal_strength:.3f})")
            
            # æ˜¾ç¤ºæ‰€æœ‰å»åº“å“ç§
            if inventory_trends['å»åº“å“ç§']:
                st.markdown("**ğŸ”´ æ‰€æœ‰å»åº“å“ç§ï¼ˆåšå¤šä¿¡å·ï¼‰:**")
                # æŒ‰ä¿¡å·å¼ºåº¦æ’åºå»åº“å“ç§
                depletion_symbols = []
                for symbol in inventory_trends['å»åº“å“ç§']:
                    change_rate = results_df[results_df['å“ç§'] == symbol]['å˜åŒ–ç‡'].iloc[0]
                    signal_strength = results_df[results_df['å“ç§'] == symbol]['ä¿¡å·å¼ºåº¦'].iloc[0]
                    depletion_symbols.append((symbol, change_rate, signal_strength))
                
                # æŒ‰ä¿¡å·å¼ºåº¦é™åºæ’åº
                depletion_symbols.sort(key=lambda x: x[2], reverse=True)
                
                # æ˜¾ç¤ºæ‰€æœ‰å»åº“å“ç§
                for symbol, change_rate, signal_strength in depletion_symbols:
                    st.write(f"â€¢ {symbol}: {change_rate:.2f}% (ä¿¡å·å¼ºåº¦: {signal_strength:.3f})")
        else:
            st.info("æš‚æ— åº“å­˜åˆ†æç»“æœ")
    
    with col2:
        st.markdown("### ğŸ’° åŸºå·®åˆ†æç»“æœ")
        if has_basis:
            opportunities, strategy = basis_results
            
            # åŸºå·®åˆ†ææ‘˜è¦
            st.metric("æŠ•èµ„æœºä¼šæ•°", len(opportunities))
            
            buy_basis_count = len([o for o in opportunities if 'ä¹°åŸºå·®' in o.opportunity_type])
            sell_basis_count = len([o for o in opportunities if 'å–åŸºå·®' in o.opportunity_type])
            
            col2_1, col2_2 = st.columns(2)
            with col2_1:
                st.metric("ä¹°åŸºå·®æœºä¼š", buy_basis_count)
            with col2_2:
                st.metric("å–åŸºå·®æœºä¼š", sell_basis_count)
            
            # æ˜¾ç¤ºæ‰€æœ‰ä¹°åŸºå·®æœºä¼š
            buy_basis_opps = [opp for opp in opportunities if 'ä¹°åŸºå·®' in opp.opportunity_type]
            sell_basis_opps = [opp for opp in opportunities if 'å–åŸºå·®' in opp.opportunity_type]
            
            # æŒ‰ç½®ä¿¡åº¦æ’åº
            buy_basis_opps.sort(key=lambda x: x.confidence, reverse=True)
            sell_basis_opps.sort(key=lambda x: x.confidence, reverse=True)
            
            if buy_basis_opps:
                st.markdown("**ğŸŸ¢ æ‰€æœ‰ä¹°åŸºå·®æœºä¼šï¼ˆåšç©ºä¿¡å·ï¼‰:**")
                for opp in buy_basis_opps:
                    st.write(f"â€¢ {opp.name}: ç½®ä¿¡åº¦ {opp.confidence:.1f}% (Z-Score: {opp.z_score:.2f})")
            
            if sell_basis_opps:
                st.markdown("**ğŸ”´ æ‰€æœ‰å–åŸºå·®æœºä¼šï¼ˆåšå¤šä¿¡å·ï¼‰:**")
                for opp in sell_basis_opps:
                    st.write(f"â€¢ {opp.name}: ç½®ä¿¡åº¦ {opp.confidence:.1f}% (Z-Score: {opp.z_score:.2f})")
        else:
            st.info("æš‚æ— åŸºå·®åˆ†æç»“æœ")
    
    # ä¿¡å·å…±æŒ¯åˆ†æ
    if has_inventory and has_basis:
        st.subheader("ğŸ¯ ä¿¡å·å…±æŒ¯åˆ†æ")
        
        # ä¿¡å·å…±æŒ¯åˆ†æé€»è¾‘è¯´æ˜
        with st.expander("ğŸ“– ä¿¡å·å…±æŒ¯åˆ†æé€»è¾‘"):
            st.markdown("""
            ### ğŸ” ä¿¡å·å…±æŒ¯åˆ†æåŸç†
            
            #### 1. å…±æŒ¯åˆ†æé€»è¾‘
            **ä¿¡å·å…±æŒ¯**æ˜¯æŒ‡åº“å­˜åˆ†æå’ŒåŸºå·®åˆ†æå¾—å‡ºç›¸åŒæ–¹å‘çš„æŠ•èµ„ä¿¡å·ï¼Œè¿™ç§æƒ…å†µä¸‹æŠ•èµ„æœºä¼šçš„å¯é æ€§æ˜¾è‘—æé«˜ã€‚
            
            #### 2. å…±æŒ¯ç±»å‹è¯†åˆ«
            
            **åšç©ºä¿¡å·å…±æŒ¯**ï¼š
            - **åº“å­˜ä¿¡å·**ï¼šç´¯åº“ï¼ˆåº“å­˜å¢åŠ ï¼‰
            - **åŸºå·®ä¿¡å·**ï¼šä¹°åŸºå·®ï¼ˆæœŸè´§è¢«é«˜ä¼°ï¼‰
            - **æŠ•èµ„é€»è¾‘**ï¼šä¾›åº”è¿‡å‰© + æœŸè´§é«˜ä¼° â†’ å¼ºçƒˆçœ‹ç©º
            - **æ“ä½œå»ºè®®**ï¼šè€ƒè™‘åšç©ºæœŸè´§æˆ–ä¹°åŸºå·®æ“ä½œ
            
            **åšå¤šä¿¡å·å…±æŒ¯**ï¼š
            - **åº“å­˜ä¿¡å·**ï¼šå»åº“ï¼ˆåº“å­˜å‡å°‘ï¼‰
            - **åŸºå·®ä¿¡å·**ï¼šå–åŸºå·®ï¼ˆç°è´§è¢«é«˜ä¼°ï¼‰
            - **æŠ•èµ„é€»è¾‘**ï¼šä¾›åº”ç´§å¼  + ç°è´§é«˜ä¼° â†’ å¼ºçƒˆçœ‹å¤š
            - **æ“ä½œå»ºè®®**ï¼šè€ƒè™‘åšå¤šæœŸè´§æˆ–å–åŸºå·®æ“ä½œ
            
            #### 3. ä¿¡å·å†²çªå¤„ç†
            
            **å†²çªæƒ…å†µ**ï¼š
            - ç´¯åº“ + å–åŸºå·®ï¼šåº“å­˜çœ‹ç©º vs åŸºå·®çœ‹å¤š
            - å»åº“ + ä¹°åŸºå·®ï¼šåº“å­˜çœ‹å¤š vs åŸºå·®çœ‹ç©º
            
            **å¤„ç†ç­–ç•¥**ï¼š
            - æ·±å…¥åˆ†æå†²çªåŸå› 
            - è€ƒè™‘æ—¶é—´å‘¨æœŸå·®å¼‚
            - è§‚æœ›æˆ–ç­‰å¾…ä¿¡å·æ˜ç¡®
            
            #### 4. æŠ•èµ„ä¼˜å…ˆçº§
            
            **ä¼˜å…ˆçº§æ’åº**ï¼š
            1. **åŒé‡å…±æŒ¯** > **å•ä¸€å¼ºä¿¡å·** > **å•ä¸€å¼±ä¿¡å·** > **ä¿¡å·å†²çª**
            2. å…±æŒ¯å“ç§çš„æŠ•èµ„æˆåŠŸæ¦‚ç‡æ›´é«˜
            3. å†²çªå“ç§éœ€è¦æ›´è°¨æ…çš„åˆ†æ
            
            #### 5. é£é™©æ§åˆ¶
            - å³ä½¿æ˜¯å…±æŒ¯ä¿¡å·ä¹Ÿè¦æ§åˆ¶ä»“ä½
            - è®¾ç½®æ­¢æŸç‚¹ï¼Œé˜²èŒƒç³»ç»Ÿæ€§é£é™©
            - å…³æ³¨å®è§‚ç»æµå’Œæ”¿ç­–å˜åŒ–
            
            ğŸ’¡ **æ ¸å¿ƒç†å¿µ**ï¼šå¤šç»´åº¦ä¿¡å·éªŒè¯ï¼Œæé«˜æŠ•èµ„å†³ç­–çš„å¯é æ€§
            """)
        
        st.markdown("---")
        
        results_df, inventory_trends, data_dict = inventory_results
        opportunities, strategy = basis_results
        
        # è·å–åŸºå·®ä¿¡å·å“ç§
        buy_basis_symbols = [opp.variety for opp in opportunities if 'ä¹°åŸºå·®' in opp.opportunity_type]
        sell_basis_symbols = [opp.variety for opp in opportunities if 'å–åŸºå·®' in opp.opportunity_type]
        
        # åšç©ºä¿¡å·å…±æŒ¯ï¼ˆç´¯åº“ + ä¹°åŸºå·®ï¼‰
        short_resonance = set(inventory_trends['ç´¯åº“å“ç§']) & set(buy_basis_symbols)
        
        # åšå¤šä¿¡å·å…±æŒ¯ï¼ˆå»åº“ + å–åŸºå·®ï¼‰
        long_resonance = set(inventory_trends['å»åº“å“ç§']) & set(sell_basis_symbols)
        
        # ä¿¡å·å†²çªï¼ˆç´¯åº“ + å–åŸºå·® æˆ– å»åº“ + ä¹°åŸºå·®ï¼‰
        conflict_1 = set(inventory_trends['ç´¯åº“å“ç§']) & set(sell_basis_symbols)  # ç´¯åº“ä½†å–åŸºå·®
        conflict_2 = set(inventory_trends['å»åº“å“ç§']) & set(buy_basis_symbols)   # å»åº“ä½†ä¹°åŸºå·®
        
        # æ˜¾ç¤ºå…±æŒ¯åˆ†æç»“æœ
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("åšç©ºä¿¡å·å…±æŒ¯", len(short_resonance))
            st.metric("åšå¤šä¿¡å·å…±æŒ¯", len(long_resonance))
        
        with col2:
            st.metric("ä¿¡å·å†²çªå“ç§", len(conflict_1) + len(conflict_2))
            total_analyzed = len(set(inventory_trends['ç´¯åº“å“ç§'] + inventory_trends['å»åº“å“ç§']) | 
                               set(buy_basis_symbols + sell_basis_symbols))
            resonance_rate = (len(short_resonance) + len(long_resonance)) / max(total_analyzed, 1) * 100
            st.metric("å…±æŒ¯ç‡", f"{resonance_rate:.1f}%")
        
        with col3:
            if short_resonance or long_resonance:
                st.success("å‘ç°ä¿¡å·å…±æŒ¯ï¼")
            else:
                st.warning("æœªå‘ç°æ˜æ˜¾å…±æŒ¯")
        
        # è¯¦ç»†å…±æŒ¯åˆ†æ
        if short_resonance or long_resonance or conflict_1 or conflict_2:
            st.subheader("ğŸ“‹ è¯¦ç»†å…±æŒ¯åˆ†æ")
            
            # åšç©ºä¿¡å·å…±æŒ¯
            if short_resonance:
                st.markdown("#### ğŸ”´ åšç©ºä¿¡å·å…±æŒ¯å“ç§")
                st.success("åº“å­˜ç´¯ç§¯ + ä¹°åŸºå·®ä¿¡å· = å¼ºçƒˆåšç©ºä¿¡å·")
                
                resonance_data = []
                for symbol in short_resonance:
                    # è·å–åº“å­˜æ•°æ®
                    inventory_change = results_df[results_df['å“ç§'] == symbol]['å˜åŒ–ç‡'].iloc[0]
                    inventory_signal = results_df[results_df['å“ç§'] == symbol]['ä¿¡å·å¼ºåº¦'].iloc[0]
                    
                    # è·å–åŸºå·®æ•°æ®
                    basis_opp = next(opp for opp in opportunities if opp.variety == symbol)
                    
                    resonance_data.append({
                        'å“ç§': symbol,
                        'åº“å­˜å˜åŒ–ç‡': f"{inventory_change:.2f}%",
                        'åº“å­˜ä¿¡å·å¼ºåº¦': f"{inventory_signal:.3f}",
                        'åŸºå·®æœºä¼šç±»å‹': basis_opp.opportunity_type,
                        'åŸºå·®ç½®ä¿¡åº¦': f"{basis_opp.confidence:.1f}%",
                        'ç»¼åˆå»ºè®®': 'å¼ºçƒˆçœ‹ç©º',
                        'æ“ä½œå»ºè®®': 'è€ƒè™‘åšç©ºæ“ä½œ'
                    })
                
                resonance_df = pd.DataFrame(resonance_data)
                st.dataframe(resonance_df, use_container_width=True)
            
            # åšå¤šä¿¡å·å…±æŒ¯
            if long_resonance:
                st.markdown("#### ğŸŸ¢ åšå¤šä¿¡å·å…±æŒ¯å“ç§")
                st.success("åº“å­˜å»åŒ– + å–åŸºå·®ä¿¡å· = å¼ºçƒˆåšå¤šä¿¡å·")
                
                resonance_data = []
                for symbol in long_resonance:
                    # è·å–åº“å­˜æ•°æ®
                    inventory_change = results_df[results_df['å“ç§'] == symbol]['å˜åŒ–ç‡'].iloc[0]
                    inventory_signal = results_df[results_df['å“ç§'] == symbol]['ä¿¡å·å¼ºåº¦'].iloc[0]
                    
                    # è·å–åŸºå·®æ•°æ®
                    basis_opp = next(opp for opp in opportunities if opp.variety == symbol)
                    
                    resonance_data.append({
                        'å“ç§': symbol,
                        'åº“å­˜å˜åŒ–ç‡': f"{inventory_change:.2f}%",
                        'åº“å­˜ä¿¡å·å¼ºåº¦': f"{inventory_signal:.3f}",
                        'åŸºå·®æœºä¼šç±»å‹': basis_opp.opportunity_type,
                        'åŸºå·®ç½®ä¿¡åº¦': f"{basis_opp.confidence:.1f}%",
                        'ç»¼åˆå»ºè®®': 'å¼ºçƒˆçœ‹å¤š',
                        'æ“ä½œå»ºè®®': 'è€ƒè™‘åšå¤šæ“ä½œ'
                    })
                
                resonance_df = pd.DataFrame(resonance_data)
                st.dataframe(resonance_df, use_container_width=True)
            
            # ä¿¡å·å†²çª
            if conflict_1 or conflict_2:
                st.markdown("#### âš ï¸ ä¿¡å·å†²çªå“ç§")
                st.warning("åº“å­˜ä¿¡å·ä¸åŸºå·®ä¿¡å·æ–¹å‘ç›¸åï¼Œéœ€è¦è°¨æ…åˆ†æ")
                
                conflict_data = []
                
                # ç´¯åº“ä½†å–åŸºå·®
                for symbol in conflict_1:
                    inventory_change = results_df[results_df['å“ç§'] == symbol]['å˜åŒ–ç‡'].iloc[0]
                    basis_opp = next(opp for opp in opportunities if opp.variety == symbol)
                    
                    conflict_data.append({
                        'å“ç§': symbol,
                        'åº“å­˜ä¿¡å·': 'ç´¯åº“ï¼ˆçœ‹ç©ºï¼‰',
                        'åŸºå·®ä¿¡å·': f"{basis_opp.opportunity_type}ï¼ˆçœ‹å¤šï¼‰",
                        'åº“å­˜å˜åŒ–ç‡': f"{inventory_change:.2f}%",
                        'åŸºå·®ç½®ä¿¡åº¦': f"{basis_opp.confidence:.1f}%",
                        'å†²çªç±»å‹': 'åº“å­˜çœ‹ç©º vs åŸºå·®çœ‹å¤š',
                        'å»ºè®®': 'è§‚æœ›æˆ–æ·±å…¥åˆ†æ'
                    })
                
                # å»åº“ä½†ä¹°åŸºå·®
                for symbol in conflict_2:
                    inventory_change = results_df[results_df['å“ç§'] == symbol]['å˜åŒ–ç‡'].iloc[0]
                    basis_opp = next(opp for opp in opportunities if opp.variety == symbol)
                    
                    conflict_data.append({
                        'å“ç§': symbol,
                        'åº“å­˜ä¿¡å·': 'å»åº“ï¼ˆçœ‹å¤šï¼‰',
                        'åŸºå·®ä¿¡å·': f"{basis_opp.opportunity_type}ï¼ˆçœ‹ç©ºï¼‰",
                        'åº“å­˜å˜åŒ–ç‡': f"{inventory_change:.2f}%",
                        'åŸºå·®ç½®ä¿¡åº¦': f"{basis_opp.confidence:.1f}%",
                        'å†²çªç±»å‹': 'åº“å­˜çœ‹å¤š vs åŸºå·®çœ‹ç©º',
                        'å»ºè®®': 'è§‚æœ›æˆ–æ·±å…¥åˆ†æ'
                    })
                
                if conflict_data:
                    conflict_df = pd.DataFrame(conflict_data)
                    st.dataframe(conflict_df, use_container_width=True)
        
        # æŠ•èµ„å»ºè®®æ€»ç»“
        st.subheader("ğŸ’¡ ç»¼åˆæŠ•èµ„å»ºè®®")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ¯ ä¼˜å…ˆå…³æ³¨å“ç§")
            priority_symbols = list(short_resonance) + list(long_resonance)
            if priority_symbols:
                for symbol in priority_symbols:
                    if symbol in short_resonance:
                        st.write(f"ğŸ”´ {symbol}: åŒé‡åšç©ºä¿¡å·")
                    else:
                        st.write(f"ğŸŸ¢ {symbol}: åŒé‡åšå¤šä¿¡å·")
            else:
                st.info("æš‚æ— æ˜æ˜¾çš„ä¿¡å·å…±æŒ¯å“ç§")
            
            # æ˜¾ç¤ºæ‰€æœ‰åšç©ºä¿¡å·å“ç§ï¼ˆåŒ…æ‹¬å•ä¸€ä¿¡å·ï¼‰
            st.markdown("#### ğŸ“‰ æ‰€æœ‰åšç©ºä¿¡å·å“ç§")
            all_short_signals = set(inventory_trends['ç´¯åº“å“ç§']) | set(buy_basis_symbols)
            if all_short_signals:
                for symbol in sorted(all_short_signals):
                    signals = []
                    if symbol in inventory_trends['ç´¯åº“å“ç§']:
                        signals.append("ç´¯åº“")
                    if symbol in buy_basis_symbols:
                        signals.append("ä¹°åŸºå·®")
                    signal_text = " + ".join(signals)
                    if len(signals) > 1:
                        st.write(f"ğŸ”´ {symbol}: {signal_text} (å…±æŒ¯)")
                    else:
                        st.write(f"ğŸŸ¡ {symbol}: {signal_text}")
            else:
                st.info("æš‚æ— åšç©ºä¿¡å·å“ç§")
        
        with col2:
            st.markdown("#### âš ï¸ è°¨æ…è§‚å¯Ÿå“ç§")
            caution_symbols = list(conflict_1) + list(conflict_2)
            if caution_symbols:
                for symbol in caution_symbols:
                    st.write(f"âš ï¸ {symbol}: ä¿¡å·å†²çªï¼Œéœ€æ·±å…¥åˆ†æ")
            else:
                st.info("æš‚æ— æ˜æ˜¾çš„ä¿¡å·å†²çªå“ç§")
            
            # æ˜¾ç¤ºæ‰€æœ‰åšå¤šä¿¡å·å“ç§ï¼ˆåŒ…æ‹¬å•ä¸€ä¿¡å·ï¼‰
            st.markdown("#### ğŸ“ˆ æ‰€æœ‰åšå¤šä¿¡å·å“ç§")
            all_long_signals = set(inventory_trends['å»åº“å“ç§']) | set(sell_basis_symbols)
            if all_long_signals:
                for symbol in sorted(all_long_signals):
                    signals = []
                    if symbol in inventory_trends['å»åº“å“ç§']:
                        signals.append("å»åº“")
                    if symbol in sell_basis_symbols:
                        signals.append("å–åŸºå·®")
                    signal_text = " + ".join(signals)
                    if len(signals) > 1:
                        st.write(f"ğŸŸ¢ {symbol}: {signal_text} (å…±æŒ¯)")
                    else:
                        st.write(f"ğŸŸ¡ {symbol}: {signal_text}")
            else:
                st.info("æš‚æ— åšå¤šä¿¡å·å“ç§")
        
        # å¯¼å‡ºç»¼åˆæŠ¥å‘Š
        st.subheader("ğŸ“¥ å¯¼å‡ºç»¼åˆæŠ¥å‘Š")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ“Š å¯¼å‡ºç»¼åˆExcelæŠ¥å‘Š"):
                try:
                    exporter = get_report_exporter()
                    filepath = exporter.create_comprehensive_report(inventory_results, basis_results)
                    
                    with open(filepath, 'rb') as f:
                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½ç»¼åˆæŠ¥å‘Š",
                            data=f.read(),
                            file_name=filepath.name,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    st.success("ç»¼åˆæŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                except Exception as e:
                    st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
        
        with col2:
            if st.button("ğŸ“ˆ å¯¼å‡ºå…±æŒ¯åˆ†æ"):
                # åˆ›å»ºå…±æŒ¯åˆ†ææ•°æ®
                resonance_analysis = []
                
                # åšç©ºå…±æŒ¯
                for symbol in short_resonance:
                    resonance_analysis.append({
                        'å“ç§': symbol,
                        'ä¿¡å·ç±»å‹': 'åšç©ºå…±æŒ¯',
                        'åº“å­˜ä¿¡å·': 'ç´¯åº“',
                        'åŸºå·®ä¿¡å·': 'ä¹°åŸºå·®',
                        'æŠ•èµ„å»ºè®®': 'çœ‹ç©ºï¼Œè€ƒè™‘åšç©ºæ“ä½œ'
                    })
                
                # åšå¤šå…±æŒ¯
                for symbol in long_resonance:
                    resonance_analysis.append({
                        'å“ç§': symbol,
                        'ä¿¡å·ç±»å‹': 'åšå¤šå…±æŒ¯',
                        'åº“å­˜ä¿¡å·': 'å»åº“',
                        'åŸºå·®ä¿¡å·': 'å–åŸºå·®',
                        'æŠ•èµ„å»ºè®®': 'çœ‹å¤šï¼Œè€ƒè™‘åšå¤šæ“ä½œ'
                    })
                
                if resonance_analysis:
                    resonance_df = pd.DataFrame(resonance_analysis)
                    csv = resonance_df.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½å…±æŒ¯åˆ†æ",
                        data=csv,
                        file_name=f"ä¿¡å·å…±æŒ¯åˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                else:
                    st.warning("æš‚æ— å…±æŒ¯ä¿¡å·å¯å¯¼å‡º")
        
        with col3:
            if st.button("ğŸ“‹ å¤åˆ¶ç»¼åˆæ‘˜è¦"):
                summary_text = f"""
ç»¼åˆåˆ†ææ‘˜è¦ ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})
=====================================
åº“å­˜åˆ†æ: {len(results_df)} ä¸ªå“ç§
åŸºå·®åˆ†æ: {len(opportunities)} ä¸ªæœºä¼š

ä¿¡å·å…±æŒ¯åˆ†æ:
- åšç©ºä¿¡å·å…±æŒ¯: {len(short_resonance)} ä¸ªå“ç§
- åšå¤šä¿¡å·å…±æŒ¯: {len(long_resonance)} ä¸ªå“ç§
- ä¿¡å·å†²çª: {len(conflict_1) + len(conflict_2)} ä¸ªå“ç§
- å…±æŒ¯ç‡: {resonance_rate:.1f}%

é‡ç‚¹å…³æ³¨å“ç§:
åšç©ºå…±æŒ¯: {', '.join(list(short_resonance)[:3]) if short_resonance else 'æ— '}
åšå¤šå…±æŒ¯: {', '.join(list(long_resonance)[:3]) if long_resonance else 'æ— '}
"""
                st.code(summary_text)
                st.info("æ‘˜è¦å·²æ˜¾ç¤ºï¼Œå¯æ‰‹åŠ¨å¤åˆ¶")
    
    else:
        st.info("éœ€è¦åŒæ—¶å®Œæˆåº“å­˜åˆ†æå’ŒåŸºå·®åˆ†ææ‰èƒ½è¿›è¡Œä¿¡å·å…±æŒ¯åˆ†æã€‚")
        
        missing_analysis = []
        if not has_inventory:
            missing_analysis.append("åº“å­˜åˆ†æ")
        if not has_basis:
            missing_analysis.append("åŸºå·®åˆ†æ")
        
        st.warning(f"ç¼ºå°‘: {', '.join(missing_analysis)}")
        
        # æä¾›å¿«é€Ÿå¯¼èˆª
        col1, col2 = st.columns(2)
        with col1:
            if not has_inventory and st.button("ğŸ”— å‰å¾€åº“å­˜åˆ†æ"):
                st.session_state.page = "åº“å­˜åˆ†æ"
                st.rerun()
        with col2:
            if not has_basis and st.button("ğŸ”— å‰å¾€åŸºå·®åˆ†æ"):
                st.session_state.page = "åŸºå·®åˆ†æ"
                st.rerun()

# ==================== ä¸»åº”ç”¨ç¨‹åº ====================

def main():
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    init_session_state()
    
    st.title("ğŸ“Š æœŸè´§åŸºæœ¬é¢ç»¼åˆåˆ†æç³»ç»Ÿ")
    st.markdown("*by 7haoge 953534947@qq.com*")
    st.markdown("---")
    
    # ç³»ç»Ÿä»‹ç»
    with st.expander("ğŸ“– ç³»ç»Ÿä»‹ç»ä¸ä½¿ç”¨æŒ‡å—", expanded=False):
        st.markdown("""
        ### ğŸ¯ ç³»ç»Ÿæ¦‚è¿°
        æœ¬ç³»ç»Ÿæ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœŸè´§åŸºæœ¬é¢åˆ†æå·¥å…·ï¼Œé€šè¿‡**åº“å­˜åˆ†æ**å’Œ**åŸºå·®åˆ†æ**ä¸¤ä¸ªç»´åº¦ï¼Œ
        ä¸ºæŠ•èµ„è€…æä¾›ç§‘å­¦çš„æŠ•èµ„å†³ç­–æ”¯æŒã€‚
        
        ### ğŸ“Š æ ¸å¿ƒåŠŸèƒ½
        
        #### 1. åº“å­˜åˆ†ææ¨¡å—
        - **åŠŸèƒ½**ï¼šåˆ†ææœŸè´§å“ç§çš„åº“å­˜å˜åŒ–è¶‹åŠ¿
        - **åŸç†**ï¼šåŸºäºåº“å­˜ä¾›éœ€å…³ç³»åˆ¤æ–­ä»·æ ¼æ–¹å‘
        - **è¾“å‡º**ï¼šç´¯åº“ï¼ˆçœ‹ç©ºï¼‰ã€å»åº“ï¼ˆçœ‹å¤šï¼‰ã€ç¨³å®šä¿¡å·
        - **åº”ç”¨**ï¼šé€‚åˆä¸­é•¿æœŸè¶‹åŠ¿åˆ¤æ–­
        
        #### 2. åŸºå·®åˆ†ææ¨¡å—  
        - **åŠŸèƒ½**ï¼šåˆ†æç°è´§ä¸æœŸè´§çš„ä»·æ ¼å·®å¼‚
        - **åŸç†**ï¼šåŸºäºç»Ÿè®¡å¥—åˆ©åŸç†ï¼Œåˆ©ç”¨åŸºå·®å›å½’ç‰¹æ€§
        - **è¾“å‡º**ï¼šä¹°åŸºå·®ï¼ˆåšç©ºï¼‰ã€å–åŸºå·®ï¼ˆåšå¤šï¼‰æœºä¼š
        - **åº”ç”¨**ï¼šé€‚åˆçŸ­ä¸­æœŸå¥—åˆ©äº¤æ˜“
        
        #### 3. ç»¼åˆåˆ†ææ¨¡å—
        - **åŠŸèƒ½**ï¼šæ•´åˆåº“å­˜å’ŒåŸºå·®åˆ†æç»“æœ
        - **åŸç†**ï¼šé€šè¿‡ä¿¡å·å…±æŒ¯æé«˜æŠ•èµ„å¯é æ€§
        - **è¾“å‡º**ï¼šå…±æŒ¯ä¿¡å·ã€å†²çªä¿¡å·ã€æŠ•èµ„ä¼˜å…ˆçº§
        - **åº”ç”¨**ï¼šæä¾›æœ€ç»ˆæŠ•èµ„å†³ç­–å»ºè®®
        
        ### ğŸ” åˆ†æé€»è¾‘
        
        **åº“å­˜åˆ†æé€»è¾‘**ï¼š
        ```
        åº“å­˜å¢åŠ  â†’ ä¾›åº”è¿‡å‰© â†’ ä»·æ ¼ä¸‹è·Œå‹åŠ› â†’ çœ‹ç©ºä¿¡å·
        åº“å­˜å‡å°‘ â†’ ä¾›åº”ç´§å¼  â†’ ä»·æ ¼ä¸Šæ¶¨åŠ¨åŠ› â†’ çœ‹å¤šä¿¡å·
        ```
        
        **åŸºå·®åˆ†æé€»è¾‘**ï¼š
        ```
        åŸºå·®å¼‚å¸¸åç¦» â†’ ä»·æ ¼å…³ç³»å¤±è¡¡ â†’ å›å½’é¢„æœŸ â†’ å¥—åˆ©æœºä¼š
        ```
        
        **ç»¼åˆåˆ†æé€»è¾‘**ï¼š
        ```
        ä¿¡å·å…±æŒ¯ â†’ å¤šç»´åº¦éªŒè¯ â†’ é«˜å¯é æ€§ â†’ ä¼˜å…ˆæŠ•èµ„
        ä¿¡å·å†²çª â†’ æ·±å…¥åˆ†æ â†’ è°¨æ…è§‚æœ› â†’ ç­‰å¾…æ˜ç¡®
        ```
        
        ### ğŸ’¡ ä½¿ç”¨å»ºè®®
        
        1. **æ–°æ‰‹ç”¨æˆ·**ï¼šå»ºè®®ä»å•æ¨¡å—åˆ†æå¼€å§‹ï¼Œç†è§£åŸºæœ¬é€»è¾‘
        2. **è¿›é˜¶ç”¨æˆ·**ï¼šä½¿ç”¨ç»¼åˆåˆ†æï¼Œå…³æ³¨ä¿¡å·å…±æŒ¯æœºä¼š
        3. **ä¸“ä¸šç”¨æˆ·**ï¼šç»“åˆé«˜çº§ç­›é€‰ï¼Œè‡ªå®šä¹‰åˆ†æå‚æ•°
        
        ### âš ï¸ é£é™©æç¤º
        
        - æœ¬ç³»ç»Ÿä»…æä¾›åˆ†æå·¥å…·ï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®
        - æŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…
        - å»ºè®®ç»“åˆå…¶ä»–åˆ†ææ–¹æ³•ç»¼åˆåˆ¤æ–­
        - æ³¨æ„æ§åˆ¶ä»“ä½å’Œè®¾ç½®æ­¢æŸ
        """)
    
    # ä¾§è¾¹æ å¯¼èˆª
    st.sidebar.title("ğŸ”§ åˆ†ææ¨¡å—é€‰æ‹©")
    
    # é¡µé¢é€‰æ‹©
    if 'page' not in st.session_state:
        st.session_state.page = "ğŸ“ˆ åº“å­˜åˆ†æ"
    
    analysis_type = st.sidebar.selectbox(
        "è¯·é€‰æ‹©åˆ†æç±»å‹",
        ["ğŸ“ˆ åº“å­˜åˆ†æ", "ğŸ’° åŸºå·®åˆ†æ", "ğŸ” ç»¼åˆåˆ†æ"],
        index=["ğŸ“ˆ åº“å­˜åˆ†æ", "ğŸ’° åŸºå·®åˆ†æ", "ğŸ” ç»¼åˆåˆ†æ"].index(st.session_state.page) if st.session_state.page in ["ğŸ“ˆ åº“å­˜åˆ†æ", "ğŸ’° åŸºå·®åˆ†æ", "ğŸ” ç»¼åˆåˆ†æ"] else 0
    )
    
    # æ›´æ–°é¡µé¢çŠ¶æ€
    st.session_state.page = analysis_type
    
    # ä¾§è¾¹æ çŠ¶æ€ä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“Š åˆ†æçŠ¶æ€")
    
    # æ˜¾ç¤ºåˆ†æçŠ¶æ€
    has_inventory = st.session_state.get('inventory_results') is not None
    has_basis = st.session_state.get('basis_results') is not None
    
    if has_inventory:
        results_df, inventory_trends, _ = st.session_state.inventory_results
        st.sidebar.success(f"âœ… åº“å­˜åˆ†æå®Œæˆ ({len(results_df)}ä¸ªå“ç§)")
    else:
        st.sidebar.info("â³ åº“å­˜åˆ†ææœªå®Œæˆ")
    
    if has_basis:
        opportunities, _ = st.session_state.basis_results
        st.sidebar.success(f"âœ… åŸºå·®åˆ†æå®Œæˆ ({len(opportunities)}ä¸ªæœºä¼š)")
    else:
        st.sidebar.info("â³ åŸºå·®åˆ†ææœªå®Œæˆ")
    
    # ç¼“å­˜ç®¡ç†
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ—‚ï¸ ç¼“å­˜ç®¡ç†")
    
    cache_info = f"å†…å­˜ç¼“å­˜: {len(cache_manager.memory_cache)} é¡¹"
    st.sidebar.info(cache_info)
    
    if st.sidebar.button("ğŸ—‘ï¸ æ¸…é™¤è¿‡æœŸç¼“å­˜"):
        cache_manager.clear_expired()
        st.sidebar.success("è¿‡æœŸç¼“å­˜å·²æ¸…é™¤")
    
    if st.sidebar.button("ğŸ”„ æ¸…é™¤æ‰€æœ‰ç¼“å­˜"):
        cache_manager.clear_expired()
        st.session_state.clear()
        st.sidebar.success("æ‰€æœ‰ç¼“å­˜å·²æ¸…é™¤")
        st.rerun()
    
    # ç³»ç»Ÿä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.subheader("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
    st.sidebar.info(f"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ä½œè€…ä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ‘¨â€ğŸ’» ä½œè€…ä¿¡æ¯")
    st.sidebar.markdown("""
    **ä½œè€…**: 7haoge  
    **é‚®ç®±**: 953534947@qq.com  
    **å¹´ä»½**: 2025.06
    """)
    
    # ä½¿ç”¨è¯´æ˜
    with st.sidebar.expander("ğŸ“– ä½¿ç”¨è¯´æ˜"):
        st.markdown("""
        **åº“å­˜åˆ†æ**ï¼š
        - åˆ†ææœŸè´§å“ç§åº“å­˜å˜åŒ–è¶‹åŠ¿
        - è¯†åˆ«ç´¯åº“ã€å»åº“ã€ç¨³å®šä¸‰ç§çŠ¶æ€
        - æä¾›æŠ•èµ„æ–¹å‘å»ºè®®
        
        **åŸºå·®åˆ†æ**ï¼š
        - åˆ†æç°è´§ä¸æœŸè´§ä»·æ ¼å·®å¼‚
        - è¯†åˆ«ä¹°åŸºå·®ã€å–åŸºå·®æœºä¼š
        - æä¾›ç½®ä¿¡åº¦è¯„ä¼°
        
        **ç»¼åˆåˆ†æ**ï¼š
        - æ•´åˆåº“å­˜å’ŒåŸºå·®åˆ†æç»“æœ
        - è¯†åˆ«ä¿¡å·å…±æŒ¯æœºä¼š
        - æä¾›ç»¼åˆæŠ•èµ„å»ºè®®
        """)
    
    # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºå¯¹åº”é¡µé¢
    if analysis_type == "ğŸ“ˆ åº“å­˜åˆ†æ":
        inventory_analysis_page()
    elif analysis_type == "ğŸ’° åŸºå·®åˆ†æ":
        basis_analysis_page()
    elif analysis_type == "ğŸ” ç»¼åˆåˆ†æ":
        comprehensive_analysis_page()
    
    # é¡µé¢åº•éƒ¨ä¿¡æ¯
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.info("ğŸ’¡ **æç¤º**: å»ºè®®å…ˆå®Œæˆåº“å­˜åˆ†æå’ŒåŸºå·®åˆ†æï¼Œå†æŸ¥çœ‹ç»¼åˆåˆ†æ")
    
    with col2:
        st.info("âš¡ **æ€§èƒ½**: ç³»ç»Ÿå·²å¯ç”¨æ™ºèƒ½ç¼“å­˜ï¼Œé‡å¤åˆ†æå°†æ›´å¿«å®Œæˆ")
    
    with col3:
        st.info("ğŸ“Š **æ•°æ®**: æ‰€æœ‰æ•°æ®æ¥æºäºakshareï¼Œè¯·ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸")
    
    # ä½œè€…ä¿¡æ¯å’Œç‰ˆæƒå£°æ˜
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666; font-size: 14px; padding: 20px;'>
        <p><strong>æœŸè´§åŸºæœ¬é¢ç»¼åˆåˆ†æç³»ç»Ÿ </strong></p>
        <p>ğŸ‘¨â€ğŸ’» ä½œè€…: <strong>7haoge</strong> | ğŸ“§ é‚®ç®±: <strong>953534947@qq.com</strong></p>
        <p>ğŸ”§ æŠ€æœ¯æ ˆ: Streamlit + AKShare + Pandas + Plotly + Scipy</p>
        <p>âš ï¸ å…è´£å£°æ˜: æœ¬ç³»ç»Ÿä»…ä¾›å­¦ä¹ ç ”ç©¶ä½¿ç”¨ï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…ã€‚</p>
        <p>Â© 2025 All Rights Reserved</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main() 